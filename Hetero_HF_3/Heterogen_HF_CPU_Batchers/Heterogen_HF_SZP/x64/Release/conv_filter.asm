; Listing generated by Microsoft (R) Optimizing Compiler Version 19.14.26430.0 

include listing.inc

INCLUDELIB OLDNAMES

EXTRN	__security_check_cookie:PROC
PUBLIC	?medianFilter@@YAXHHHPEAM0@Z			; medianFilter
PUBLIC	?mergeSort@@YAXPEAM@Z				; mergeSort
PUBLIC	__real@408f400000000000
PUBLIC	__real@412e848000000000
EXTRN	__GSHandlerCheck:PROC
EXTRN	__security_cookie:QWORD
EXTRN	_fltused:DWORD
;	COMDAT pdata
pdata	SEGMENT
$pdata$?medianFilter@@YAXHHHPEAM0@Z DD imagerel $LN44@medianFilt
	DD	imagerel $LN44@medianFilt+48
	DD	imagerel $unwind$?medianFilter@@YAXHHHPEAM0@Z
pdata	ENDS
;	COMDAT pdata
pdata	SEGMENT
$pdata$5$?medianFilter@@YAXHHHPEAM0@Z DD imagerel $LN44@medianFilt+48
	DD	imagerel $LN44@medianFilt+366
	DD	imagerel $chain$5$?medianFilter@@YAXHHHPEAM0@Z
pdata	ENDS
;	COMDAT pdata
pdata	SEGMENT
$pdata$6$?medianFilter@@YAXHHHPEAM0@Z DD imagerel $LN44@medianFilt+366
	DD	imagerel $LN44@medianFilt+367
	DD	imagerel $chain$6$?medianFilter@@YAXHHHPEAM0@Z
pdata	ENDS
;	COMDAT pdata
pdata	SEGMENT
$pdata$?mergeSort@@YAXPEAM@Z DD imagerel $LN144
	DD	imagerel $LN144+3880
	DD	imagerel $unwind$?mergeSort@@YAXPEAM@Z
;	COMDAT __real@412e848000000000
CONST	SEGMENT
__real@412e848000000000 DQ 0412e848000000000r	; 1e+06
CONST	ENDS
;	COMDAT __real@408f400000000000
CONST	SEGMENT
__real@408f400000000000 DQ 0408f400000000000r	; 1000
CONST	ENDS
;	COMDAT xdata
xdata	SEGMENT
$unwind$?mergeSort@@YAXPEAM@Z DD 0123f01H
	DD	0d83fH
	DD	01c83aH
	DD	02b835H
	DD	03a830H
	DD	04982bH
	DD	058826H
	DD	067821H
	DD	07681cH
	DD	011010aH
xdata	ENDS
;	COMDAT xdata
xdata	SEGMENT
$chain$6$?medianFilter@@YAXHHHPEAM0@Z DD 021H
	DD	imagerel $LN44@medianFilt
	DD	imagerel $LN44@medianFilt+48
	DD	imagerel $unwind$?medianFilter@@YAXHHHPEAM0@Z
xdata	ENDS
;	COMDAT xdata
xdata	SEGMENT
$chain$5$?medianFilter@@YAXHHHPEAM0@Z DD 0c2321H
	DD	016f423H
	DD	017d41cH
	DD	0187410H
	DD	01f640cH
	DD	01e5408H
	DD	01c3404H
	DD	imagerel $LN44@medianFilt
	DD	imagerel $LN44@medianFilt+48
	DD	imagerel $unwind$?medianFilter@@YAXHHHPEAM0@Z
xdata	ENDS
;	COMDAT xdata
xdata	SEGMENT
$unwind$?medianFilter@@YAXHHHPEAM0@Z DD 042819H
	DD	0190116H
	DD	0c00de00fH
	DD	imagerel __GSHandlerCheck
	DD	0a0H
xdata	ENDS
; Function compile flags: /Ogtpy
; File d:\d_strabi\d dokumentumai\bme\heterogén számítási rendszerek\hf\kismacska\hetero_hf_3\heterogen_hf_cpu_batchers\heterogen_hf_szp\_src\conv_filter.cpp
;	COMDAT ?mergeSort@@YAXPEAM@Z
_TEXT	SEGMENT
tomb$ = 144
?mergeSort@@YAXPEAM@Z PROC				; mergeSort, COMDAT

; 47   : void mergeSort(float * tomb) {

$LN144:
	mov	rax, rsp
	sub	rsp, 136				; 00000088H

; 48   : 	float tmp;
; 49   : 	// 4x4
; 50   : 	PIXEL_COMPARE_AND_SWAP(0, 1);

	vmovss	xmm1, DWORD PTR [rcx]
	vmovss	xmm0, DWORD PTR [rcx+4]
	vcomiss	xmm1, xmm0
	vmovaps	XMMWORD PTR [rax-24], xmm6
	vmovaps	XMMWORD PTR [rax-40], xmm7
	vmovaps	XMMWORD PTR [rax-56], xmm8
	vmovaps	XMMWORD PTR [rax-72], xmm9
	vmovaps	XMMWORD PTR [rax-88], xmm10
	vmovaps	XMMWORD PTR [rax-104], xmm11
	vmovaps	XMMWORD PTR [rax-120], xmm12
	vmovaps	XMMWORD PTR [rsp], xmm13
	vmovaps	xmm2, xmm1
	jbe	SHORT $LN2@mergeSort
	vmovss	DWORD PTR [rcx], xmm0
	vmovaps	xmm2, xmm0
	vmovaps	xmm0, xmm1
	vmovss	DWORD PTR [rcx+4], xmm1
$LN2@mergeSort:

; 51   : 	PIXEL_COMPARE_AND_SWAP(2, 3);

	vmovss	xmm3, DWORD PTR [rcx+8]
	vmovss	xmm4, DWORD PTR [rcx+12]
	vcomiss	xmm3, xmm4
	vmovaps	xmm1, xmm3
	jbe	SHORT $LN3@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm4
	vmovaps	xmm1, xmm4
	vmovaps	xmm4, xmm3
	vmovss	DWORD PTR [rcx+12], xmm3
$LN3@mergeSort:

; 52   : 	PIXEL_COMPARE_AND_SWAP(0, 2);

	vcomiss	xmm2, xmm1
	vmovaps	xmm3, xmm1
	jbe	SHORT $LN4@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm2
	vmovaps	xmm3, xmm2
	vmovaps	xmm2, xmm1
	vmovss	DWORD PTR [rcx], xmm1
$LN4@mergeSort:

; 53   : 	PIXEL_COMPARE_AND_SWAP(1, 3);

	vcomiss	xmm0, xmm4
	jbe	SHORT $LN5@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm0
	vmovaps	xmm0, xmm4
	vmovss	DWORD PTR [rcx+4], xmm4
$LN5@mergeSort:

; 54   : 	PIXEL_COMPARE_AND_SWAP(1, 2);

	vcomiss	xmm0, xmm3
	vmovaps	xmm6, xmm0
	jbe	SHORT $LN6@mergeSort
	vmovss	DWORD PTR [rcx+4], xmm3
	vmovaps	xmm6, xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+8], xmm0
$LN6@mergeSort:

; 55   : 	//printf("Hello");
; 56   : 	PIXEL_COMPARE_AND_SWAP(4, 5);

	vmovss	xmm1, DWORD PTR [rcx+16]
	vmovss	xmm5, DWORD PTR [rcx+20]
	vcomiss	xmm1, xmm5
	vmovaps	xmm0, xmm1
	jbe	SHORT $LN7@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm5
	vmovaps	xmm0, xmm5
	vmovaps	xmm5, xmm1
	vmovss	DWORD PTR [rcx+20], xmm1
$LN7@mergeSort:

; 57   : 	PIXEL_COMPARE_AND_SWAP(6, 7);

	vmovss	xmm1, DWORD PTR [rcx+24]
	vmovss	xmm4, DWORD PTR [rcx+28]
	vcomiss	xmm1, xmm4
	vmovaps	xmm7, xmm1
	jbe	SHORT $LN8@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm4
	vmovaps	xmm7, xmm4
	vmovaps	xmm4, xmm1
	vmovss	DWORD PTR [rcx+28], xmm1
$LN8@mergeSort:

; 58   : 	PIXEL_COMPARE_AND_SWAP(4, 6);

	vcomiss	xmm0, xmm7
	vmovaps	xmm1, xmm7
	jbe	SHORT $LN9@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm0
	vmovaps	xmm1, xmm0
	vmovaps	xmm0, xmm7
	vmovss	DWORD PTR [rcx+16], xmm7
$LN9@mergeSort:

; 59   : 	PIXEL_COMPARE_AND_SWAP(5, 7);

	vcomiss	xmm5, xmm4
	vmovaps	xmm7, xmm5
	jbe	SHORT $LN10@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm4
	vmovaps	xmm7, xmm4
	vmovaps	xmm4, xmm5
	vmovss	DWORD PTR [rcx+28], xmm5
$LN10@mergeSort:

; 60   : 	PIXEL_COMPARE_AND_SWAP(5, 6);

	vcomiss	xmm7, xmm1
	vmovaps	xmm8, xmm7
	jbe	SHORT $LN11@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm1
	vmovaps	xmm8, xmm1
	vmovaps	xmm1, xmm7
	vmovss	DWORD PTR [rcx+24], xmm7
$LN11@mergeSort:

; 61   : 
; 62   : 	PIXEL_COMPARE_AND_SWAP(0, 4);

	vcomiss	xmm2, xmm0
	jbe	SHORT $LN12@mergeSort
	vmovss	DWORD PTR [rcx], xmm0
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+16], xmm2
$LN12@mergeSort:

; 63   : 	PIXEL_COMPARE_AND_SWAP(1, 5); 

	vcomiss	xmm6, xmm8
	vmovaps	xmm5, xmm8
	jbe	SHORT $LN13@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm6
	vmovaps	xmm5, xmm6
	vmovaps	xmm6, xmm8
	vmovss	DWORD PTR [rcx+4], xmm8
$LN13@mergeSort:

; 64   : 	PIXEL_COMPARE_AND_SWAP(2, 6);

	vcomiss	xmm3, xmm1
	vmovaps	xmm7, xmm3
	jbe	SHORT $LN14@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm1
	vmovaps	xmm7, xmm1
	vmovaps	xmm1, xmm3
	vmovss	DWORD PTR [rcx+24], xmm3
$LN14@mergeSort:

; 65   : 	PIXEL_COMPARE_AND_SWAP(3, 7);

	vmovss	xmm2, DWORD PTR [rcx+12]
	vcomiss	xmm2, xmm4
	jbe	SHORT $LN15@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm2
	vmovaps	xmm2, xmm4
	vmovss	DWORD PTR [rcx+12], xmm4
$LN15@mergeSort:

; 66   : 
; 67   : 	PIXEL_COMPARE_AND_SWAP(2, 4); 

	vcomiss	xmm7, xmm0
	vmovaps	xmm4, xmm7
	jbe	SHORT $LN16@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm0
	vmovaps	xmm4, xmm0
	vmovaps	xmm0, xmm7
	vmovss	DWORD PTR [rcx+16], xmm7
$LN16@mergeSort:

; 68   : 	PIXEL_COMPARE_AND_SWAP(3, 5);

	vcomiss	xmm2, xmm5
	vmovaps	xmm3, xmm2
	jbe	SHORT $LN17@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm5
	vmovaps	xmm3, xmm5
	vmovaps	xmm5, xmm2
	vmovss	DWORD PTR [rcx+20], xmm2
$LN17@mergeSort:

; 69   : 
; 70   : 	PIXEL_COMPARE_AND_SWAP(1, 2);

	vcomiss	xmm6, xmm4
	jbe	SHORT $LN18@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm6
	vmovss	DWORD PTR [rcx+4], xmm4
$LN18@mergeSort:

; 71   : 	PIXEL_COMPARE_AND_SWAP(3, 4);

	vcomiss	xmm3, xmm0
	jbe	SHORT $LN19@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm3
	vmovss	DWORD PTR [rcx+12], xmm0
$LN19@mergeSort:

; 72   : 	PIXEL_COMPARE_AND_SWAP(5, 6);

	vcomiss	xmm5, xmm1
	jbe	SHORT $LN20@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm5
	vmovss	DWORD PTR [rcx+20], xmm1
$LN20@mergeSort:

; 73   : 
; 74   : 	// 4x4	
; 75   : 	PIXEL_COMPARE_AND_SWAP(8, 9);

	vmovss	xmm2, DWORD PTR [rcx+32]
	vmovss	xmm0, DWORD PTR [rcx+36]
	vcomiss	xmm2, xmm0
	vmovaps	xmm1, xmm2
	jbe	SHORT $LN21@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm0
	vmovaps	xmm1, xmm0
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+36], xmm2
$LN21@mergeSort:

; 76   : 	PIXEL_COMPARE_AND_SWAP(10, 11);

	vmovss	xmm3, DWORD PTR [rcx+40]
	vmovss	xmm4, DWORD PTR [rcx+44]
	vcomiss	xmm3, xmm4
	vmovaps	xmm2, xmm3
	jbe	SHORT $LN22@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm4
	vmovaps	xmm2, xmm4
	vmovaps	xmm4, xmm3
	vmovss	DWORD PTR [rcx+44], xmm3
$LN22@mergeSort:

; 77   : 	PIXEL_COMPARE_AND_SWAP(8, 10);

	vcomiss	xmm1, xmm2
	vmovaps	xmm3, xmm2
	jbe	SHORT $LN23@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm1
	vmovaps	xmm3, xmm1
	vmovaps	xmm1, xmm2
	vmovss	DWORD PTR [rcx+32], xmm2
$LN23@mergeSort:

; 78   : 	PIXEL_COMPARE_AND_SWAP(9, 11);

	vcomiss	xmm0, xmm4
	jbe	SHORT $LN24@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm0
	vmovaps	xmm0, xmm4
	vmovss	DWORD PTR [rcx+36], xmm4
$LN24@mergeSort:

; 79   : 	PIXEL_COMPARE_AND_SWAP(9, 10);

	vcomiss	xmm0, xmm3
	vmovaps	xmm7, xmm0
	jbe	SHORT $LN25@mergeSort
	vmovss	DWORD PTR [rcx+36], xmm3
	vmovaps	xmm7, xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+40], xmm0
$LN25@mergeSort:

; 80   : 
; 81   : 	PIXEL_COMPARE_AND_SWAP(12, 13);

	vmovss	xmm0, DWORD PTR [rcx+48]
	vmovss	xmm4, DWORD PTR [rcx+52]
	vcomiss	xmm0, xmm4
	vmovaps	xmm2, xmm0
	jbe	SHORT $LN26@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm4
	vmovaps	xmm2, xmm4
	vmovaps	xmm4, xmm0
	vmovss	DWORD PTR [rcx+52], xmm0
$LN26@mergeSort:

; 82   : 	PIXEL_COMPARE_AND_SWAP(14, 15);

	vmovss	xmm0, DWORD PTR [rcx+56]
	vmovss	xmm5, DWORD PTR [rcx+60]
	vcomiss	xmm0, xmm5
	vmovaps	xmm6, xmm0
	jbe	SHORT $LN27@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm5
	vmovaps	xmm6, xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+60], xmm0
$LN27@mergeSort:

; 83   : 	PIXEL_COMPARE_AND_SWAP(12, 14);

	vcomiss	xmm2, xmm6
	vmovaps	xmm0, xmm6
	jbe	SHORT $LN28@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm2
	vmovaps	xmm0, xmm2
	vmovaps	xmm2, xmm6
	vmovss	DWORD PTR [rcx+48], xmm6
$LN28@mergeSort:

; 84   : 	PIXEL_COMPARE_AND_SWAP(13, 15);

	vcomiss	xmm4, xmm5
	vmovaps	xmm6, xmm4
	jbe	SHORT $LN29@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm5
	vmovaps	xmm6, xmm5
	vmovaps	xmm5, xmm4
	vmovss	DWORD PTR [rcx+60], xmm4
$LN29@mergeSort:

; 85   : 	PIXEL_COMPARE_AND_SWAP(13, 14);

	vcomiss	xmm6, xmm0
	vmovaps	xmm8, xmm6
	jbe	SHORT $LN30@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm0
	vmovaps	xmm8, xmm0
	vmovaps	xmm0, xmm6
	vmovss	DWORD PTR [rcx+56], xmm6
$LN30@mergeSort:

; 86   : 
; 87   : 	PIXEL_COMPARE_AND_SWAP(8, 12);

	vcomiss	xmm1, xmm2
	vmovaps	xmm4, xmm2
	jbe	SHORT $LN31@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm1
	vmovaps	xmm4, xmm1
	vmovaps	xmm1, xmm2
	vmovss	DWORD PTR [rcx+32], xmm2
$LN31@mergeSort:

; 88   : 	PIXEL_COMPARE_AND_SWAP(9, 13); 

	vcomiss	xmm7, xmm8
	vmovaps	xmm6, xmm8
	jbe	SHORT $LN32@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm7
	vmovaps	xmm6, xmm7
	vmovaps	xmm7, xmm8
	vmovss	DWORD PTR [rcx+36], xmm8
$LN32@mergeSort:

; 89   : 	PIXEL_COMPARE_AND_SWAP(10, 14);

	vcomiss	xmm3, xmm0
	vmovaps	xmm8, xmm3
	jbe	SHORT $LN33@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm0
	vmovaps	xmm8, xmm0
	vmovaps	xmm0, xmm3
	vmovss	DWORD PTR [rcx+56], xmm3
$LN33@mergeSort:

; 90   : 	PIXEL_COMPARE_AND_SWAP(11, 15);

	vmovss	xmm3, DWORD PTR [rcx+44]
	vcomiss	xmm3, xmm5
	jbe	SHORT $LN34@mergeSort
	vmovss	DWORD PTR [rcx+60], xmm3
	vmovaps	xmm3, xmm5
	vmovss	DWORD PTR [rcx+44], xmm5
$LN34@mergeSort:

; 91   : 
; 92   : 	PIXEL_COMPARE_AND_SWAP(10, 12); 

	vcomiss	xmm8, xmm4
	vmovaps	xmm2, xmm8
	jbe	SHORT $LN35@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm4
	vmovaps	xmm2, xmm4
	vmovaps	xmm4, xmm8
	vmovss	DWORD PTR [rcx+48], xmm8
$LN35@mergeSort:

; 93   : 	PIXEL_COMPARE_AND_SWAP(11, 13);

	vcomiss	xmm3, xmm6
	vmovaps	xmm5, xmm3
	jbe	SHORT $LN36@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm6
	vmovaps	xmm5, xmm6
	vmovaps	xmm6, xmm3
	vmovss	DWORD PTR [rcx+52], xmm3
$LN36@mergeSort:

; 94   : 
; 95   : 	PIXEL_COMPARE_AND_SWAP(9, 10);

	vcomiss	xmm7, xmm2
	vmovaps	xmm8, xmm7
	jbe	SHORT $LN37@mergeSort
	vmovss	DWORD PTR [rcx+36], xmm2
	vmovaps	xmm8, xmm2
	vmovaps	xmm2, xmm7
	vmovss	DWORD PTR [rcx+40], xmm7
$LN37@mergeSort:

; 96   : 	PIXEL_COMPARE_AND_SWAP(11, 12);

	vcomiss	xmm5, xmm4
	vmovaps	xmm7, xmm5
	jbe	SHORT $LN38@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm4
	vmovaps	xmm7, xmm4
	vmovaps	xmm4, xmm5
	vmovss	DWORD PTR [rcx+48], xmm5
$LN38@mergeSort:

; 97   : 	PIXEL_COMPARE_AND_SWAP(13, 14);

	vcomiss	xmm6, xmm0
	vmovaps	xmm5, xmm6
	jbe	SHORT $LN39@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm0
	vmovaps	xmm5, xmm0
	vmovaps	xmm0, xmm6
	vmovss	DWORD PTR [rcx+56], xmm6
$LN39@mergeSort:

; 98   : 
; 99   : 
; 100  : 	PIXEL_COMPARE_AND_SWAP(0, 8); 

	vmovss	xmm3, DWORD PTR [rcx]
	vcomiss	xmm3, xmm1
	jbe	SHORT $LN40@mergeSort
	vmovss	DWORD PTR [rcx], xmm1
	vmovaps	xmm1, xmm3
	vmovss	DWORD PTR [rcx+32], xmm3
$LN40@mergeSort:

; 101  : 	PIXEL_COMPARE_AND_SWAP(1, 9); 

	vmovss	xmm3, DWORD PTR [rcx+4]
	vcomiss	xmm3, xmm8
	jbe	SHORT $LN41@mergeSort
	vmovss	DWORD PTR [rcx+4], xmm8
	vmovaps	xmm8, xmm3
	vmovss	DWORD PTR [rcx+36], xmm3
$LN41@mergeSort:

; 102  : 	PIXEL_COMPARE_AND_SWAP(2, 10); 

	vmovss	xmm3, DWORD PTR [rcx+8]
	vcomiss	xmm3, xmm2
	jbe	SHORT $LN42@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+40], xmm3
$LN42@mergeSort:

; 103  : 	PIXEL_COMPARE_AND_SWAP(3, 11); 

	vmovss	xmm3, DWORD PTR [rcx+12]
	vcomiss	xmm3, xmm7
	jbe	SHORT $LN43@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm7
	vmovaps	xmm7, xmm3
	vmovss	DWORD PTR [rcx+44], xmm3
$LN43@mergeSort:

; 104  : 	PIXEL_COMPARE_AND_SWAP(4, 12); 

	vmovss	xmm3, DWORD PTR [rcx+16]
	vcomiss	xmm3, xmm4
	jbe	SHORT $LN44@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm3
	vmovaps	xmm3, xmm4
	vmovss	DWORD PTR [rcx+16], xmm4
$LN44@mergeSort:

; 105  : 	PIXEL_COMPARE_AND_SWAP(5, 13); 

	vmovss	xmm4, DWORD PTR [rcx+20]
	vcomiss	xmm4, xmm5
	jbe	SHORT $LN45@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm4
	vmovaps	xmm4, xmm5
	vmovss	DWORD PTR [rcx+20], xmm5
$LN45@mergeSort:

; 106  : 	PIXEL_COMPARE_AND_SWAP(6, 14); 

	vmovss	xmm5, DWORD PTR [rcx+24]
	vcomiss	xmm5, xmm0
	jbe	SHORT $LN46@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+24], xmm0
$LN46@mergeSort:

; 107  : 	PIXEL_COMPARE_AND_SWAP(7, 15); 

	vmovss	xmm0, DWORD PTR [rcx+28]
	vmovss	xmm6, DWORD PTR [rcx+60]
	vcomiss	xmm0, xmm6
	jbe	SHORT $LN47@mergeSort
	vmovss	DWORD PTR [rcx+60], xmm0
	vmovaps	xmm0, xmm6
	vmovss	DWORD PTR [rcx+28], xmm6
$LN47@mergeSort:

; 108  : 
; 109  : 
; 110  : 	PIXEL_COMPARE_AND_SWAP(4, 8); 

	vcomiss	xmm3, xmm1
	vmovaps	xmm6, xmm3
	jbe	SHORT $LN48@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm1
	vmovaps	xmm6, xmm1
	vmovaps	xmm1, xmm3
	vmovss	DWORD PTR [rcx+32], xmm3
$LN48@mergeSort:

; 111  : 	PIXEL_COMPARE_AND_SWAP(5, 9); 

	vcomiss	xmm4, xmm8
	vmovaps	xmm9, xmm4
	jbe	SHORT $LN49@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm8
	vmovaps	xmm9, xmm8
	vmovaps	xmm8, xmm4
	vmovss	DWORD PTR [rcx+36], xmm4
$LN49@mergeSort:

; 112  : 	PIXEL_COMPARE_AND_SWAP(6, 10); 

	vcomiss	xmm5, xmm2
	vmovaps	xmm3, xmm5
	jbe	SHORT $LN50@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm2
	vmovaps	xmm3, xmm2
	vmovaps	xmm2, xmm5
	vmovss	DWORD PTR [rcx+40], xmm5
$LN50@mergeSort:

; 113  : 	PIXEL_COMPARE_AND_SWAP(7, 11); 

	vcomiss	xmm0, xmm7
	vmovaps	xmm4, xmm0
	jbe	SHORT $LN51@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm7
	vmovaps	xmm4, xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+44], xmm0
$LN51@mergeSort:

; 114  : 
; 115  : 	PIXEL_COMPARE_AND_SWAP(2, 4); 

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm6
	vmovaps	xmm13, xmm0
	jbe	SHORT $LN52@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm6
	vmovaps	xmm13, xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+16], xmm0
$LN52@mergeSort:

; 116  : 	PIXEL_COMPARE_AND_SWAP(3, 5); 

	vmovss	xmm0, DWORD PTR [rcx+12]
	vcomiss	xmm0, xmm9
	vmovaps	xmm12, xmm0
	jbe	SHORT $LN53@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm9
	vmovaps	xmm12, xmm9
	vmovaps	xmm9, xmm0
	vmovss	DWORD PTR [rcx+20], xmm0
$LN53@mergeSort:

; 117  : 	PIXEL_COMPARE_AND_SWAP(6, 8);

	vcomiss	xmm3, xmm1
	vmovaps	xmm11, xmm3
	jbe	SHORT $LN54@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm1
	vmovaps	xmm11, xmm1
	vmovaps	xmm1, xmm3
	vmovss	DWORD PTR [rcx+32], xmm3
$LN54@mergeSort:

; 118  : 	PIXEL_COMPARE_AND_SWAP(7, 9);

	vcomiss	xmm4, xmm8
	vmovaps	xmm10, xmm4
	jbe	SHORT $LN55@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm8
	vmovaps	xmm10, xmm8
	vmovaps	xmm8, xmm4
	vmovss	DWORD PTR [rcx+36], xmm4
$LN55@mergeSort:

; 119  : 	PIXEL_COMPARE_AND_SWAP(10, 12); 

	vmovss	xmm0, DWORD PTR [rcx+48]
	vcomiss	xmm2, xmm0
	vmovaps	xmm4, xmm2
	jbe	SHORT $LN56@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm0
	vmovaps	xmm4, xmm0
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+48], xmm2
$LN56@mergeSort:

; 120  : 	PIXEL_COMPARE_AND_SWAP(11, 13); 

	vmovss	xmm2, DWORD PTR [rcx+52]
	vcomiss	xmm7, xmm2
	vmovaps	xmm3, xmm7
	jbe	SHORT $LN57@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm2
	vmovaps	xmm3, xmm2
	vmovaps	xmm2, xmm7
	vmovss	DWORD PTR [rcx+52], xmm7
$LN57@mergeSort:

; 121  : 
; 122  : 	PIXEL_COMPARE_AND_SWAP(1, 2); 

	vmovss	xmm5, DWORD PTR [rcx+4]
	vcomiss	xmm5, xmm13
	jbe	SHORT $LN58@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm5
	vmovss	DWORD PTR [rcx+4], xmm13
$LN58@mergeSort:

; 123  : 	PIXEL_COMPARE_AND_SWAP(3, 4); 

	vcomiss	xmm12, xmm6
	jbe	SHORT $LN59@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm12
	vmovss	DWORD PTR [rcx+12], xmm6
$LN59@mergeSort:

; 124  : 	PIXEL_COMPARE_AND_SWAP(5, 6); 

	vcomiss	xmm9, xmm11
	jbe	SHORT $LN60@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm9
	vmovss	DWORD PTR [rcx+20], xmm11
$LN60@mergeSort:

; 125  : 	PIXEL_COMPARE_AND_SWAP(7, 8); 

	vcomiss	xmm10, xmm1
	jbe	SHORT $LN61@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm10
	vmovss	DWORD PTR [rcx+28], xmm1
$LN61@mergeSort:

; 126  : 	PIXEL_COMPARE_AND_SWAP(9, 10); 

	vcomiss	xmm8, xmm4
	jbe	SHORT $LN62@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm8
	vmovss	DWORD PTR [rcx+36], xmm4
$LN62@mergeSort:

; 127  : 	PIXEL_COMPARE_AND_SWAP(11, 12); 

	vcomiss	xmm3, xmm0
	jbe	SHORT $LN63@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm3
	vmovss	DWORD PTR [rcx+44], xmm0
$LN63@mergeSort:

; 128  : 	PIXEL_COMPARE_AND_SWAP(13, 14); 

	vmovss	xmm0, DWORD PTR [rcx+56]
	vcomiss	xmm2, xmm0
	jbe	SHORT $LN64@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm2
	vmovss	DWORD PTR [rcx+52], xmm0
$LN64@mergeSort:

; 129  : 
; 130  : // Eddig 8x8-as (16 bemenet)
; 131  : 
; 132  : 	//4x4
; 133  : 	PIXEL_COMPARE_AND_SWAP(16, 17);

	vmovss	xmm0, DWORD PTR [rcx+64]
	vmovss	xmm1, DWORD PTR [rcx+68]
	vcomiss	xmm0, xmm1
	vmovaps	xmm10, xmm0
	jbe	SHORT $LN65@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm1
	vmovaps	xmm10, xmm1
	vmovaps	xmm1, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN65@mergeSort:

; 134  : 	PIXEL_COMPARE_AND_SWAP(18, 19);

	vmovss	xmm0, DWORD PTR [rcx+72]
	vmovss	xmm3, DWORD PTR [rcx+76]
	vcomiss	xmm0, xmm3
	vmovaps	xmm2, xmm0
	jbe	SHORT $LN66@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm3
	vmovaps	xmm2, xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+76], xmm0
$LN66@mergeSort:

; 135  : 	PIXEL_COMPARE_AND_SWAP(20, 21);

	vmovss	xmm0, DWORD PTR [rcx+80]
	vmovss	xmm6, DWORD PTR [rcx+84]
	vcomiss	xmm0, xmm6
	vmovaps	xmm5, xmm0
	jbe	SHORT $LN67@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm6
	vmovaps	xmm5, xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+84], xmm0
$LN67@mergeSort:

; 136  : 	PIXEL_COMPARE_AND_SWAP(22, 23);

	vmovss	xmm4, DWORD PTR [rcx+88]
	vmovss	xmm9, DWORD PTR [rcx+92]
	vcomiss	xmm4, xmm9
	vmovaps	xmm0, xmm4
	jbe	SHORT $LN68@mergeSort
	vmovaps	xmm0, xmm9
	vmovss	DWORD PTR [rcx+88], xmm0
	vmovss	DWORD PTR [rcx+92], xmm4
	vmovaps	xmm9, xmm4
$LN68@mergeSort:

; 137  : 
; 138  : 	PIXEL_COMPARE_AND_SWAP(16, 18);

	vcomiss	xmm10, xmm2
	vmovaps	xmm7, xmm2
	jbe	SHORT $LN69@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm10
	vmovaps	xmm7, xmm10
	vmovaps	xmm10, xmm2
	vmovss	DWORD PTR [rcx+64], xmm2
$LN69@mergeSort:

; 139  : 	PIXEL_COMPARE_AND_SWAP(20, 22);

	vcomiss	xmm5, xmm0
	vmovaps	xmm8, xmm0
	jbe	SHORT $LN70@mergeSort
	vmovss	DWORD PTR [rcx+88], xmm5
	vmovaps	xmm8, xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+80], xmm0
$LN70@mergeSort:

; 140  : 	PIXEL_COMPARE_AND_SWAP(17, 19);

	vcomiss	xmm1, xmm3
	vmovaps	xmm0, xmm1
	jbe	SHORT $LN71@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm3
	vmovaps	xmm0, xmm3
	vmovaps	xmm3, xmm1
	vmovss	DWORD PTR [rcx+76], xmm1
$LN71@mergeSort:

; 141  : 	PIXEL_COMPARE_AND_SWAP(21, 23);

	vcomiss	xmm6, xmm9
	vmovaps	xmm1, xmm6
	jbe	SHORT $LN72@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm9
	vmovaps	xmm1, xmm9
	vmovaps	xmm9, xmm6
	vmovss	DWORD PTR [rcx+92], xmm6
$LN72@mergeSort:

; 142  : 
; 143  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vcomiss	xmm0, xmm7
	vmovaps	xmm6, xmm0
	jbe	SHORT $LN73@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm7
	vmovaps	xmm6, xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+72], xmm0
$LN73@mergeSort:

; 144  : 	PIXEL_COMPARE_AND_SWAP(21, 22);

	vcomiss	xmm1, xmm8
	vmovaps	xmm0, xmm1
	jbe	SHORT $LN74@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm8
	vmovaps	xmm0, xmm8
	vmovaps	xmm8, xmm1
	vmovss	DWORD PTR [rcx+88], xmm1
$LN74@mergeSort:

; 145  : 
; 146  : 
; 147  : 	PIXEL_COMPARE_AND_SWAP(16, 20);

	vcomiss	xmm10, xmm5
	vmovaps	xmm4, xmm5
	jbe	SHORT $LN75@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm10
	vmovaps	xmm4, xmm10
	vmovaps	xmm10, xmm5
	vmovss	DWORD PTR [rcx+64], xmm5
$LN75@mergeSort:

; 148  : 	PIXEL_COMPARE_AND_SWAP(17, 21);

	vcomiss	xmm6, xmm0
	vmovaps	xmm2, xmm0
	jbe	SHORT $LN76@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm6
	vmovaps	xmm2, xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN76@mergeSort:

; 149  : 	PIXEL_COMPARE_AND_SWAP(18, 22);

	vcomiss	xmm7, xmm8
	vmovaps	xmm1, xmm7
	jbe	SHORT $LN77@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm8
	vmovaps	xmm1, xmm8
	vmovaps	xmm8, xmm7
	vmovss	DWORD PTR [rcx+88], xmm7
$LN77@mergeSort:

; 150  : 	PIXEL_COMPARE_AND_SWAP(19, 23);

	vcomiss	xmm3, xmm9
	jbe	SHORT $LN78@mergeSort
	vmovss	DWORD PTR [rcx+92], xmm3
	vmovaps	xmm3, xmm9
	vmovss	DWORD PTR [rcx+76], xmm9
$LN78@mergeSort:

; 151  : 
; 152  : 	PIXEL_COMPARE_AND_SWAP(18, 20);

	vcomiss	xmm1, xmm4
	vmovaps	xmm0, xmm1
	jbe	SHORT $LN79@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm4
	vmovaps	xmm0, xmm4
	vmovaps	xmm4, xmm1
	vmovss	DWORD PTR [rcx+80], xmm1
$LN79@mergeSort:

; 153  : 	PIXEL_COMPARE_AND_SWAP(19, 21);

	vcomiss	xmm3, xmm2
	vmovaps	xmm1, xmm3
	jbe	SHORT $LN80@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm2
	vmovaps	xmm1, xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+84], xmm3
$LN80@mergeSort:

; 154  : 
; 155  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vcomiss	xmm6, xmm0
	vmovaps	xmm5, xmm0
	jbe	SHORT $LN81@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm6
	vmovaps	xmm5, xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN81@mergeSort:

; 156  : 	PIXEL_COMPARE_AND_SWAP(19, 20);

	vcomiss	xmm1, xmm4
	vmovaps	xmm3, xmm4
	jbe	SHORT $LN82@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm1
	vmovaps	xmm3, xmm1
	vmovaps	xmm1, xmm4
	vmovss	DWORD PTR [rcx+76], xmm4
$LN82@mergeSort:

; 157  : 	PIXEL_COMPARE_AND_SWAP(21, 22);

	vcomiss	xmm2, xmm8
	vmovaps	xmm4, xmm2
	jbe	SHORT $LN83@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm8
	vmovaps	xmm4, xmm8
	vmovaps	xmm8, xmm2
	vmovss	DWORD PTR [rcx+88], xmm2
$LN83@mergeSort:

; 158  : 
; 159  : 
; 160  : 	PIXEL_COMPARE_AND_SWAP(16, 24);

	vmovss	xmm2, DWORD PTR [rcx+96]
	vcomiss	xmm10, xmm2
	jbe	SHORT $LN84@mergeSort
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+64], xmm2
	vmovaps	xmm2, xmm10
	vmovss	DWORD PTR [rcx+96], xmm10
	vmovaps	xmm10, xmm0
$LN84@mergeSort:

; 161  : 
; 162  : 	PIXEL_COMPARE_AND_SWAP(20, 24);

	vcomiss	xmm3, xmm2
	vmovaps	xmm7, xmm3
	jbe	SHORT $LN85@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm2
	vmovaps	xmm7, xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+96], xmm3
$LN85@mergeSort:

; 163  : 
; 164  : 	PIXEL_COMPARE_AND_SWAP(18, 20);

	vcomiss	xmm5, xmm7
	vmovaps	xmm9, xmm5
	jbe	SHORT $LN86@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm7
	vmovaps	xmm9, xmm7
	vmovaps	xmm7, xmm5
	vmovss	DWORD PTR [rcx+80], xmm5
$LN86@mergeSort:

; 165  : 	PIXEL_COMPARE_AND_SWAP(19, 21);

	vcomiss	xmm1, xmm4
	vmovaps	xmm0, xmm1
	jbe	SHORT $LN87@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm4
	vmovaps	xmm0, xmm4
	vmovaps	xmm4, xmm1
	vmovss	DWORD PTR [rcx+84], xmm1
$LN87@mergeSort:

; 166  : 	PIXEL_COMPARE_AND_SWAP(22, 24);

	vcomiss	xmm8, xmm2
	vmovaps	xmm11, xmm8
	jbe	SHORT $LN88@mergeSort
	vmovss	DWORD PTR [rcx+88], xmm2
	vmovaps	xmm11, xmm2
	vmovaps	xmm2, xmm8
	vmovss	DWORD PTR [rcx+96], xmm8
$LN88@mergeSort:

; 167  : 
; 168  : 	//cmpswap(19, 21);
; 169  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vcomiss	xmm6, xmm9
	vmovaps	xmm3, xmm6
	jbe	SHORT $LN89@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm9
	vmovaps	xmm3, xmm9
	vmovaps	xmm9, xmm6
	vmovss	DWORD PTR [rcx+72], xmm6
$LN89@mergeSort:

; 170  : 	PIXEL_COMPARE_AND_SWAP(19, 20);

	vcomiss	xmm0, xmm7
	vmovaps	xmm5, xmm0
	jbe	SHORT $LN90@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm7
	vmovaps	xmm5, xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+80], xmm0
$LN90@mergeSort:

; 171  : 	PIXEL_COMPARE_AND_SWAP(21, 22);

	vcomiss	xmm4, xmm11
	vmovaps	xmm6, xmm4
	jbe	SHORT $LN91@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm11
	vmovaps	xmm6, xmm11
	vmovaps	xmm11, xmm4
	vmovss	DWORD PTR [rcx+88], xmm4
$LN91@mergeSort:

; 172  : 	PIXEL_COMPARE_AND_SWAP(23, 24);

	vmovss	xmm0, DWORD PTR [rcx+92]
	vcomiss	xmm0, xmm2
	vmovaps	xmm4, xmm0
	jbe	SHORT $LN92@mergeSort
	vmovss	DWORD PTR [rcx+92], xmm2
	vmovaps	xmm4, xmm2
	vmovaps	xmm2, xmm0
	vmovss	DWORD PTR [rcx+96], xmm0
$LN92@mergeSort:

; 173  : 	//Eddig egy 8x8-as (De ez csak 9 bemenet)
; 174  : 
; 175  : // 16x16 
; 176  : 	PIXEL_COMPARE_AND_SWAP(0, 16);

	vmovss	xmm0, DWORD PTR [rcx]
	vcomiss	xmm0, xmm10
	jbe	SHORT $LN93@mergeSort
	vmovss	DWORD PTR [rcx], xmm10
	vmovaps	xmm10, xmm0
	vmovss	DWORD PTR [rcx+64], xmm0
$LN93@mergeSort:

; 177  : 	PIXEL_COMPARE_AND_SWAP(1, 17);

	vmovss	xmm0, DWORD PTR [rcx+4]
	vcomiss	xmm0, xmm3
	jbe	SHORT $LN94@mergeSort
	vmovss	DWORD PTR [rcx+4], xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN94@mergeSort:

; 178  : 	PIXEL_COMPARE_AND_SWAP(2, 18);

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm9
	jbe	SHORT $LN95@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm9
	vmovaps	xmm9, xmm0
	vmovss	DWORD PTR [rcx+72], xmm0
$LN95@mergeSort:

; 179  : 	PIXEL_COMPARE_AND_SWAP(3, 19);

	vmovss	xmm0, DWORD PTR [rcx+12]
	vcomiss	xmm0, xmm5
	jbe	SHORT $LN96@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+76], xmm0
$LN96@mergeSort:

; 180  : 	PIXEL_COMPARE_AND_SWAP(4, 20);

	vmovss	xmm0, DWORD PTR [rcx+16]
	vcomiss	xmm0, xmm7
	jbe	SHORT $LN97@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+80], xmm0
$LN97@mergeSort:

; 181  : 	PIXEL_COMPARE_AND_SWAP(5, 21);

	vmovss	xmm0, DWORD PTR [rcx+20]
	vcomiss	xmm0, xmm6
	jbe	SHORT $LN98@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+84], xmm0
$LN98@mergeSort:

; 182  : 	PIXEL_COMPARE_AND_SWAP(6, 22);

	vmovss	xmm0, DWORD PTR [rcx+24]
	vcomiss	xmm0, xmm11
	jbe	SHORT $LN99@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm11
	vmovaps	xmm11, xmm0
	vmovss	DWORD PTR [rcx+88], xmm0
$LN99@mergeSort:

; 183  : 	PIXEL_COMPARE_AND_SWAP(7, 23);

	vmovss	xmm0, DWORD PTR [rcx+28]
	vcomiss	xmm0, xmm4
	jbe	SHORT $LN100@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm4
	vmovaps	xmm4, xmm0
	vmovss	DWORD PTR [rcx+92], xmm0
$LN100@mergeSort:

; 184  : 	PIXEL_COMPARE_AND_SWAP(8, 24);

	vmovss	xmm0, DWORD PTR [rcx+32]
	vcomiss	xmm0, xmm2
	jbe	SHORT $LN101@mergeSort
	vmovss	DWORD PTR [rcx+96], xmm0
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+32], xmm2
$LN101@mergeSort:

; 185  : 
; 186  : 
; 187  : 	PIXEL_COMPARE_AND_SWAP(8, 16);

	vcomiss	xmm0, xmm10
	jbe	SHORT $LN102@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm0
	vmovaps	xmm0, xmm10
	vmovss	DWORD PTR [rcx+32], xmm10
$LN102@mergeSort:

; 188  : 	PIXEL_COMPARE_AND_SWAP(9, 17);

	vmovss	xmm1, DWORD PTR [rcx+36]
	vcomiss	xmm1, xmm3
	jbe	SHORT $LN103@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm1
	vmovaps	xmm1, xmm3
	vmovss	DWORD PTR [rcx+36], xmm3
$LN103@mergeSort:

; 189  : 	PIXEL_COMPARE_AND_SWAP(10, 18);

	vmovss	xmm2, DWORD PTR [rcx+40]
	vcomiss	xmm2, xmm9
	jbe	SHORT $LN104@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm2
	vmovaps	xmm2, xmm9
	vmovss	DWORD PTR [rcx+40], xmm9
$LN104@mergeSort:

; 190  : 	PIXEL_COMPARE_AND_SWAP(11, 19);

	vmovss	xmm3, DWORD PTR [rcx+44]
	vcomiss	xmm3, xmm5
	jbe	SHORT $LN105@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm3
	vmovaps	xmm3, xmm5
	vmovss	DWORD PTR [rcx+44], xmm5
$LN105@mergeSort:

; 191  : 	PIXEL_COMPARE_AND_SWAP(12, 20);

	vmovss	xmm10, DWORD PTR [rcx+48]
	vcomiss	xmm10, xmm7
	jbe	SHORT $LN106@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm10
	vmovaps	xmm10, xmm7
	vmovss	DWORD PTR [rcx+48], xmm7
$LN106@mergeSort:

; 192  : 	PIXEL_COMPARE_AND_SWAP(13, 21);

	vmovss	xmm9, DWORD PTR [rcx+52]
	vcomiss	xmm9, xmm6
	jbe	SHORT $LN107@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm9
	vmovaps	xmm9, xmm6
	vmovss	DWORD PTR [rcx+52], xmm6
$LN107@mergeSort:

; 193  : 	PIXEL_COMPARE_AND_SWAP(14, 22);

	vmovss	xmm8, DWORD PTR [rcx+56]
	vcomiss	xmm8, xmm11
	jbe	SHORT $LN108@mergeSort
	vmovss	DWORD PTR [rcx+88], xmm8
	vmovaps	xmm8, xmm11
	vmovss	DWORD PTR [rcx+56], xmm11
$LN108@mergeSort:

; 194  : 	PIXEL_COMPARE_AND_SWAP(15, 23);

	vmovss	xmm7, DWORD PTR [rcx+60]
	vcomiss	xmm7, xmm4
	jbe	SHORT $LN109@mergeSort
	vmovss	DWORD PTR [rcx+92], xmm7
	vmovaps	xmm7, xmm4
	vmovss	DWORD PTR [rcx+60], xmm4
$LN109@mergeSort:

; 195  : 
; 196  : 
; 197  : 	PIXEL_COMPARE_AND_SWAP(4, 8);

	vmovss	xmm6, DWORD PTR [rcx+16]
	vcomiss	xmm6, xmm0
	jbe	SHORT $LN110@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+16], xmm0
$LN110@mergeSort:

; 198  : 	PIXEL_COMPARE_AND_SWAP(5, 9);

	vmovss	xmm5, DWORD PTR [rcx+20]
	vcomiss	xmm5, xmm1
	jbe	SHORT $LN111@mergeSort
	vmovss	DWORD PTR [rcx+36], xmm5
	vmovaps	xmm5, xmm1
	vmovss	DWORD PTR [rcx+20], xmm1
$LN111@mergeSort:

; 199  : 	PIXEL_COMPARE_AND_SWAP(6, 10);

	vmovss	xmm4, DWORD PTR [rcx+24]
	vcomiss	xmm4, xmm2
	jbe	SHORT $LN112@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm4
	vmovaps	xmm4, xmm2
	vmovss	DWORD PTR [rcx+24], xmm2
$LN112@mergeSort:

; 200  : 	PIXEL_COMPARE_AND_SWAP(7, 11);

	vmovss	xmm2, DWORD PTR [rcx+28]
	vcomiss	xmm2, xmm3
	jbe	SHORT $LN113@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+28], xmm3
$LN113@mergeSort:

; 201  : 
; 202  : 	PIXEL_COMPARE_AND_SWAP(12, 16);

	vmovss	xmm0, DWORD PTR [rcx+64]
	vcomiss	xmm10, xmm0
	jbe	SHORT $LN114@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm10
	vmovaps	xmm10, xmm0
	vmovss	DWORD PTR [rcx+48], xmm0
$LN114@mergeSort:

; 203  : 	PIXEL_COMPARE_AND_SWAP(13, 17);

	vmovss	xmm0, DWORD PTR [rcx+68]
	vcomiss	xmm9, xmm0
	jbe	SHORT $LN115@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm9
	vmovaps	xmm9, xmm0
	vmovss	DWORD PTR [rcx+52], xmm0
$LN115@mergeSort:

; 204  : 	PIXEL_COMPARE_AND_SWAP(14, 18);

	vmovss	xmm0, DWORD PTR [rcx+72]
	vcomiss	xmm8, xmm0
	jbe	SHORT $LN116@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm8
	vmovaps	xmm8, xmm0
	vmovss	DWORD PTR [rcx+56], xmm0
$LN116@mergeSort:

; 205  : 	PIXEL_COMPARE_AND_SWAP(15, 19);

	vmovss	xmm0, DWORD PTR [rcx+76]
	vcomiss	xmm7, xmm0
	jbe	SHORT $LN117@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+60], xmm0
$LN117@mergeSort:

; 206  : 
; 207  : 	PIXEL_COMPARE_AND_SWAP(20, 21);

	vmovss	xmm1, DWORD PTR [rcx+80]
	vmovss	xmm0, DWORD PTR [rcx+84]
	vcomiss	xmm1, xmm0
	jbe	SHORT $LN118@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm1
	vmovaps	xmm1, xmm0
	vmovss	DWORD PTR [rcx+80], xmm0
$LN118@mergeSort:

; 208  : 
; 209  : 
; 210  : 	PIXEL_COMPARE_AND_SWAP(2, 4);

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm6
	jbe	SHORT $LN119@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm0
	vmovss	DWORD PTR [rcx+8], xmm6
$LN119@mergeSort:

; 211  : 	PIXEL_COMPARE_AND_SWAP(3, 5);

	vmovss	xmm0, DWORD PTR [rcx+12]
	vcomiss	xmm0, xmm5
	jbe	SHORT $LN120@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm0
	vmovss	DWORD PTR [rcx+12], xmm5
$LN120@mergeSort:

; 212  : 	PIXEL_COMPARE_AND_SWAP(6, 8);

	vmovss	xmm0, DWORD PTR [rcx+32]
	vcomiss	xmm4, xmm0
	jbe	SHORT $LN121@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm4
	vmovss	DWORD PTR [rcx+24], xmm0
$LN121@mergeSort:

; 213  : 	PIXEL_COMPARE_AND_SWAP(7, 9);

	vmovss	xmm0, DWORD PTR [rcx+36]
	vcomiss	xmm2, xmm0
	jbe	SHORT $LN122@mergeSort
	vmovss	DWORD PTR [rcx+36], xmm2
	vmovss	DWORD PTR [rcx+28], xmm0
$LN122@mergeSort:

; 214  : 	PIXEL_COMPARE_AND_SWAP(10, 12);

	vmovss	xmm0, DWORD PTR [rcx+40]
	vcomiss	xmm0, xmm10
	jbe	SHORT $LN123@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm0
	vmovss	DWORD PTR [rcx+40], xmm10
$LN123@mergeSort:

; 215  : 	PIXEL_COMPARE_AND_SWAP(11, 13);

	vmovss	xmm0, DWORD PTR [rcx+44]
	vcomiss	xmm0, xmm9
	jbe	SHORT $LN124@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm0
	vmovss	DWORD PTR [rcx+44], xmm9
$LN124@mergeSort:

; 216  : 	PIXEL_COMPARE_AND_SWAP(14, 16);

	vmovss	xmm0, DWORD PTR [rcx+64]
	vcomiss	xmm8, xmm0
	jbe	SHORT $LN125@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm8
	vmovss	DWORD PTR [rcx+56], xmm0
$LN125@mergeSort:

; 217  : 	PIXEL_COMPARE_AND_SWAP(15, 17);

	vmovss	xmm0, DWORD PTR [rcx+68]
	vcomiss	xmm7, xmm0
	jbe	SHORT $LN126@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm7
	vmovss	DWORD PTR [rcx+60], xmm0
$LN126@mergeSort:

; 218  : 	PIXEL_COMPARE_AND_SWAP(18, 20);

	vmovss	xmm0, DWORD PTR [rcx+72]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN127@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm0
	vmovss	DWORD PTR [rcx+72], xmm1
$LN127@mergeSort:

; 219  : 	PIXEL_COMPARE_AND_SWAP(19, 21);

	vmovss	xmm0, DWORD PTR [rcx+76]
	vmovss	xmm1, DWORD PTR [rcx+84]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN128@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm0
	vmovss	DWORD PTR [rcx+76], xmm1
$LN128@mergeSort:

; 220  : 	PIXEL_COMPARE_AND_SWAP(22, 24);

	vmovss	xmm0, DWORD PTR [rcx+88]
	vmovss	xmm1, DWORD PTR [rcx+96]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN129@mergeSort
	vmovss	DWORD PTR [rcx+96], xmm0
	vmovss	DWORD PTR [rcx+88], xmm1
$LN129@mergeSort:

; 221  : 
; 222  : 
; 223  : 	PIXEL_COMPARE_AND_SWAP(1, 2);

	vmovss	xmm0, DWORD PTR [rcx+4]
	vmovss	xmm1, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN130@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm0
	vmovss	DWORD PTR [rcx+4], xmm1
$LN130@mergeSort:

; 224  : 	PIXEL_COMPARE_AND_SWAP(3, 4);

	vmovss	xmm0, DWORD PTR [rcx+12]
	vmovss	xmm1, DWORD PTR [rcx+16]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN131@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm0
	vmovss	DWORD PTR [rcx+12], xmm1
$LN131@mergeSort:

; 225  : 	PIXEL_COMPARE_AND_SWAP(5, 6);

	vmovss	xmm0, DWORD PTR [rcx+20]
	vmovss	xmm1, DWORD PTR [rcx+24]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN132@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm0
	vmovss	DWORD PTR [rcx+20], xmm1
$LN132@mergeSort:

; 226  : 	PIXEL_COMPARE_AND_SWAP(7, 8);

	vmovss	xmm0, DWORD PTR [rcx+28]
	vmovss	xmm1, DWORD PTR [rcx+32]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN133@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm0
	vmovss	DWORD PTR [rcx+28], xmm1
$LN133@mergeSort:

; 227  : 	PIXEL_COMPARE_AND_SWAP(9, 10);

	vmovss	xmm0, DWORD PTR [rcx+36]
	vmovss	xmm1, DWORD PTR [rcx+40]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN134@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm0
	vmovss	DWORD PTR [rcx+36], xmm1
$LN134@mergeSort:

; 228  : 	PIXEL_COMPARE_AND_SWAP(11, 12);

	vmovss	xmm0, DWORD PTR [rcx+44]
	vmovss	xmm1, DWORD PTR [rcx+48]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN135@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm0
	vmovss	DWORD PTR [rcx+44], xmm1
$LN135@mergeSort:

; 229  : 	PIXEL_COMPARE_AND_SWAP(13, 14);

	vmovss	xmm0, DWORD PTR [rcx+52]
	vmovss	xmm1, DWORD PTR [rcx+56]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN136@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm0
	vmovss	DWORD PTR [rcx+52], xmm1
$LN136@mergeSort:

; 230  : 	PIXEL_COMPARE_AND_SWAP(15, 16);

	vmovss	xmm0, DWORD PTR [rcx+60]
	vmovss	xmm1, DWORD PTR [rcx+64]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN137@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm0
	vmovss	DWORD PTR [rcx+60], xmm1
$LN137@mergeSort:

; 231  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vmovss	xmm0, DWORD PTR [rcx+68]
	vmovss	xmm1, DWORD PTR [rcx+72]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN138@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm0
	vmovss	DWORD PTR [rcx+68], xmm1
$LN138@mergeSort:

; 232  : 	PIXEL_COMPARE_AND_SWAP(19, 20);

	vmovss	xmm0, DWORD PTR [rcx+76]
	vmovss	xmm1, DWORD PTR [rcx+80]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN139@mergeSort
	vmovss	DWORD PTR [rcx+80], xmm0
	vmovss	DWORD PTR [rcx+76], xmm1
$LN139@mergeSort:

; 233  : 	PIXEL_COMPARE_AND_SWAP(21, 22);

	vmovss	xmm0, DWORD PTR [rcx+84]
	vmovss	xmm1, DWORD PTR [rcx+88]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN140@mergeSort
	vmovss	DWORD PTR [rcx+88], xmm0
	vmovss	DWORD PTR [rcx+84], xmm1
$LN140@mergeSort:

; 234  : 	PIXEL_COMPARE_AND_SWAP(23, 24);

	vmovss	xmm0, DWORD PTR [rcx+92]
	vmovss	xmm1, DWORD PTR [rcx+96]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN141@mergeSort
	vmovss	DWORD PTR [rcx+96], xmm0
	vmovss	DWORD PTR [rcx+92], xmm1
$LN141@mergeSort:

; 235  : }

	vmovaps	xmm6, XMMWORD PTR [rsp+112]
	vmovaps	xmm7, XMMWORD PTR [rsp+96]
	vmovaps	xmm8, XMMWORD PTR [rsp+80]
	vmovaps	xmm9, XMMWORD PTR [rsp+64]
	vmovaps	xmm10, XMMWORD PTR [rsp+48]
	vmovaps	xmm11, XMMWORD PTR [rsp+32]
	vmovaps	xmm12, XMMWORD PTR [rsp+16]
	vmovaps	xmm13, XMMWORD PTR [rsp]
	add	rsp, 136				; 00000088H
	ret	0
?mergeSort@@YAXPEAM@Z ENDP				; mergeSort
_TEXT	ENDS
END
