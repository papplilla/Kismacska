; Listing generated by Microsoft (R) Optimizing Compiler Version 19.14.26430.0 

include listing.inc

INCLUDELIB OLDNAMES

EXTRN	__security_check_cookie:PROC
PUBLIC	?medianFilter@@YAXHHHHHPEAM0@Z			; medianFilter
PUBLIC	?mergeSort@@YAXPEAM@Z				; mergeSort
PUBLIC	__real@408f400000000000
PUBLIC	__real@412e848000000000
EXTRN	__GSHandlerCheck:PROC
EXTRN	__security_cookie:QWORD
EXTRN	_fltused:DWORD
;	COMDAT pdata
pdata	SEGMENT
$pdata$?medianFilter@@YAXHHHHHPEAM0@Z DD imagerel $LN43
	DD	imagerel $LN43+50
	DD	imagerel $unwind$?medianFilter@@YAXHHHHHPEAM0@Z
pdata	ENDS
;	COMDAT pdata
pdata	SEGMENT
$pdata$7$?medianFilter@@YAXHHHHHPEAM0@Z DD imagerel $LN43+50
	DD	imagerel $LN43+420
	DD	imagerel $chain$7$?medianFilter@@YAXHHHHHPEAM0@Z
pdata	ENDS
;	COMDAT pdata
pdata	SEGMENT
$pdata$8$?medianFilter@@YAXHHHHHPEAM0@Z DD imagerel $LN43+420
	DD	imagerel $LN43+444
	DD	imagerel $chain$8$?medianFilter@@YAXHHHHHPEAM0@Z
pdata	ENDS
;	COMDAT pdata
pdata	SEGMENT
$pdata$?mergeSort@@YAXPEAM@Z DD imagerel $LN110
	DD	imagerel $LN110+2997
	DD	imagerel $unwind$?mergeSort@@YAXPEAM@Z
;	COMDAT __real@412e848000000000
CONST	SEGMENT
__real@412e848000000000 DQ 0412e848000000000r	; 1e+06
CONST	ENDS
;	COMDAT __real@408f400000000000
CONST	SEGMENT
__real@408f400000000000 DQ 0408f400000000000r	; 1000
CONST	ENDS
;	COMDAT xdata
xdata	SEGMENT
$unwind$?mergeSort@@YAXPEAM@Z DD 0144501H
	DD	0e845H
	DD	01d840H
	DD	02c83aH
	DD	03b835H
	DD	04a830H
	DD	05982bH
	DD	068826H
	DD	077821H
	DD	08681cH
	DD	013010aH
xdata	ENDS
;	COMDAT xdata
xdata	SEGMENT
$chain$8$?medianFilter@@YAXHHHHHPEAM0@Z DD 021H
	DD	imagerel $LN43
	DD	imagerel $LN43+50
	DD	imagerel $unwind$?medianFilter@@YAXHHHHHPEAM0@Z
xdata	ENDS
;	COMDAT xdata
xdata	SEGMENT
$chain$7$?medianFilter@@YAXHHHHHPEAM0@Z DD 0105521H
	DD	016f455H
	DD	017e451H
	DD	018d427H
	DD	019c423H
	DD	01a741fH
	DD	01f6413H
	DD	01e540fH
	DD	01c3404H
	DD	imagerel $LN43
	DD	imagerel $LN43+50
	DD	imagerel $unwind$?medianFilter@@YAXHHHHHPEAM0@Z
xdata	ENDS
;	COMDAT xdata
xdata	SEGMENT
$unwind$?medianFilter@@YAXHHHHHPEAM0@Z DD 021c19H
	DD	01b010aH
	DD	imagerel __GSHandlerCheck
	DD	0a0H
xdata	ENDS
; Function compile flags: /Ogtpy
; File d:\d_strabi\d dokumentumai\bme\heterogén számítási rendszerek\hf\kismacska\hetero_hf_3\heterogen_hf_cpu_batchers\heterogen_hf_szp\_src\conv_filter.cpp
;	COMDAT ?mergeSort@@YAXPEAM@Z
_TEXT	SEGMENT
arr$ = 160
?mergeSort@@YAXPEAM@Z PROC				; mergeSort, COMDAT

; 28   : {

$LN110:
	mov	rax, rsp
	sub	rsp, 152				; 00000098H

; 29   : 	float tmp;
; 30   : 	// 4x4
; 31   : 	PIXEL_COMPARE_AND_SWAP(0, 1);

	vmovss	xmm2, DWORD PTR [rcx]
	vmovss	xmm0, DWORD PTR [rcx+4]
	vcomiss	xmm2, xmm0
	vmovaps	XMMWORD PTR [rax-24], xmm6
	vmovaps	XMMWORD PTR [rax-40], xmm7
	vmovaps	XMMWORD PTR [rax-56], xmm8
	vmovaps	XMMWORD PTR [rax-72], xmm9
	vmovaps	XMMWORD PTR [rax-88], xmm10
	vmovaps	XMMWORD PTR [rax-104], xmm11
	vmovaps	XMMWORD PTR [rax-120], xmm12
	vmovaps	XMMWORD PTR [rsp+16], xmm13
	vmovaps	XMMWORD PTR [rsp], xmm14
	vmovaps	xmm1, xmm2
	jbe	SHORT $LN2@mergeSort
	vmovss	DWORD PTR [rcx], xmm0
	vmovaps	xmm1, xmm0
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+4], xmm2
$LN2@mergeSort:

; 32   : 	PIXEL_COMPARE_AND_SWAP(2, 3);

	vmovss	xmm3, DWORD PTR [rcx+8]
	vmovss	xmm4, DWORD PTR [rcx+12]
	vcomiss	xmm3, xmm4
	vmovaps	xmm2, xmm3
	jbe	SHORT $LN3@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm4
	vmovaps	xmm2, xmm4
	vmovaps	xmm4, xmm3
	vmovss	DWORD PTR [rcx+12], xmm3
$LN3@mergeSort:

; 33   : 	PIXEL_COMPARE_AND_SWAP(0, 2);

	vcomiss	xmm1, xmm2
	vmovaps	xmm3, xmm2
	jbe	SHORT $LN4@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm1
	vmovaps	xmm3, xmm1
	vmovaps	xmm1, xmm2
	vmovss	DWORD PTR [rcx], xmm2
$LN4@mergeSort:

; 34   : 	PIXEL_COMPARE_AND_SWAP(1, 3);

	vcomiss	xmm0, xmm4
	jbe	SHORT $LN5@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm0
	vmovaps	xmm0, xmm4
	vmovss	DWORD PTR [rcx+4], xmm4
$LN5@mergeSort:

; 35   : 	PIXEL_COMPARE_AND_SWAP(1, 2);

	vcomiss	xmm0, xmm3
	vmovaps	xmm6, xmm0
	jbe	SHORT $LN6@mergeSort
	vmovss	DWORD PTR [rcx+4], xmm3
	vmovaps	xmm6, xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+8], xmm0
$LN6@mergeSort:

; 36   : 
; 37   : 	PIXEL_COMPARE_AND_SWAP(4, 5);

	vmovss	xmm2, DWORD PTR [rcx+16]
	vmovss	xmm5, DWORD PTR [rcx+20]
	vcomiss	xmm2, xmm5
	vmovaps	xmm0, xmm2
	jbe	SHORT $LN7@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm5
	vmovaps	xmm0, xmm5
	vmovaps	xmm5, xmm2
	vmovss	DWORD PTR [rcx+20], xmm2
$LN7@mergeSort:

; 38   : 	PIXEL_COMPARE_AND_SWAP(6, 7);

	vmovss	xmm2, DWORD PTR [rcx+24]
	vmovss	xmm4, DWORD PTR [rcx+28]
	vcomiss	xmm2, xmm4
	vmovaps	xmm7, xmm2
	jbe	SHORT $LN8@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm4
	vmovaps	xmm7, xmm4
	vmovaps	xmm4, xmm2
	vmovss	DWORD PTR [rcx+28], xmm2
$LN8@mergeSort:

; 39   : 	PIXEL_COMPARE_AND_SWAP(4, 6);

	vcomiss	xmm0, xmm7
	vmovaps	xmm2, xmm7
	jbe	SHORT $LN9@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm0
	vmovaps	xmm2, xmm0
	vmovaps	xmm0, xmm7
	vmovss	DWORD PTR [rcx+16], xmm7
$LN9@mergeSort:

; 40   : 	PIXEL_COMPARE_AND_SWAP(5, 7);

	vcomiss	xmm5, xmm4
	vmovaps	xmm7, xmm5
	jbe	SHORT $LN10@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm4
	vmovaps	xmm7, xmm4
	vmovaps	xmm4, xmm5
	vmovss	DWORD PTR [rcx+28], xmm5
$LN10@mergeSort:

; 41   : 	PIXEL_COMPARE_AND_SWAP(5, 6);

	vcomiss	xmm7, xmm2
	vmovaps	xmm8, xmm7
	jbe	SHORT $LN11@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm2
	vmovaps	xmm8, xmm2
	vmovaps	xmm2, xmm7
	vmovss	DWORD PTR [rcx+24], xmm7
$LN11@mergeSort:

; 42   : 
; 43   : 	PIXEL_COMPARE_AND_SWAP(0, 4);

	vcomiss	xmm1, xmm0
	jbe	SHORT $LN12@mergeSort
	vmovss	DWORD PTR [rcx], xmm0
	vmovaps	xmm0, xmm1
	vmovss	DWORD PTR [rcx+16], xmm1
$LN12@mergeSort:

; 44   : 	PIXEL_COMPARE_AND_SWAP(1, 5); 

	vcomiss	xmm6, xmm8
	vmovaps	xmm5, xmm8
	jbe	SHORT $LN13@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm6
	vmovaps	xmm5, xmm6
	vmovaps	xmm6, xmm8
	vmovss	DWORD PTR [rcx+4], xmm8
$LN13@mergeSort:

; 45   : 	PIXEL_COMPARE_AND_SWAP(2, 6);

	vcomiss	xmm3, xmm2
	vmovaps	xmm7, xmm3
	jbe	SHORT $LN14@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm2
	vmovaps	xmm7, xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+24], xmm3
$LN14@mergeSort:

; 46   : 	PIXEL_COMPARE_AND_SWAP(3, 7);

	vmovss	xmm1, DWORD PTR [rcx+12]
	vcomiss	xmm1, xmm4
	jbe	SHORT $LN15@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm1
	vmovaps	xmm1, xmm4
	vmovss	DWORD PTR [rcx+12], xmm4
$LN15@mergeSort:

; 47   : 
; 48   : 	PIXEL_COMPARE_AND_SWAP(2, 4); 

	vcomiss	xmm7, xmm0
	vmovaps	xmm4, xmm7
	jbe	SHORT $LN16@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm0
	vmovaps	xmm4, xmm0
	vmovaps	xmm0, xmm7
	vmovss	DWORD PTR [rcx+16], xmm7
$LN16@mergeSort:

; 49   : 	PIXEL_COMPARE_AND_SWAP(3, 5);

	vcomiss	xmm1, xmm5
	vmovaps	xmm3, xmm1
	jbe	SHORT $LN17@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm5
	vmovaps	xmm3, xmm5
	vmovaps	xmm5, xmm1
	vmovss	DWORD PTR [rcx+20], xmm1
$LN17@mergeSort:

; 50   : 
; 51   : 	PIXEL_COMPARE_AND_SWAP(1, 2);

	vcomiss	xmm6, xmm4
	jbe	SHORT $LN18@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm6
	vmovss	DWORD PTR [rcx+4], xmm4
$LN18@mergeSort:

; 52   : 	PIXEL_COMPARE_AND_SWAP(3, 4);

	vcomiss	xmm3, xmm0
	jbe	SHORT $LN19@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm3
	vmovss	DWORD PTR [rcx+12], xmm0
$LN19@mergeSort:

; 53   : 	PIXEL_COMPARE_AND_SWAP(5, 6);

	vcomiss	xmm5, xmm2
	jbe	SHORT $LN20@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm5
	vmovss	DWORD PTR [rcx+20], xmm2
$LN20@mergeSort:

; 54   : 
; 55   : 	// 4x4	
; 56   : 	PIXEL_COMPARE_AND_SWAP(8, 9);

	vmovss	xmm1, DWORD PTR [rcx+32]
	vmovss	xmm0, DWORD PTR [rcx+36]
	vcomiss	xmm1, xmm0
	vmovaps	xmm4, xmm1
	jbe	SHORT $LN21@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm0
	vmovaps	xmm4, xmm0
	vmovaps	xmm0, xmm1
	vmovss	DWORD PTR [rcx+36], xmm1
$LN21@mergeSort:

; 57   : 	PIXEL_COMPARE_AND_SWAP(10, 11);

	vmovss	xmm3, DWORD PTR [rcx+40]
	vmovss	xmm2, DWORD PTR [rcx+44]
	vcomiss	xmm3, xmm2
	vmovaps	xmm1, xmm3
	jbe	SHORT $LN22@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm2
	vmovaps	xmm1, xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+44], xmm3
$LN22@mergeSort:

; 58   : 	PIXEL_COMPARE_AND_SWAP(8, 10);

	vcomiss	xmm4, xmm1
	vmovaps	xmm3, xmm1
	jbe	SHORT $LN23@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm4
	vmovaps	xmm3, xmm4
	vmovaps	xmm4, xmm1
	vmovss	DWORD PTR [rcx+32], xmm1
$LN23@mergeSort:

; 59   : 	PIXEL_COMPARE_AND_SWAP(9, 11);

	vcomiss	xmm0, xmm2
	jbe	SHORT $LN24@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm0
	vmovaps	xmm0, xmm2
	vmovss	DWORD PTR [rcx+36], xmm2
$LN24@mergeSort:

; 60   : 	PIXEL_COMPARE_AND_SWAP(9, 10);

	vcomiss	xmm0, xmm3
	vmovaps	xmm8, xmm0
	jbe	SHORT $LN25@mergeSort
	vmovss	DWORD PTR [rcx+36], xmm3
	vmovaps	xmm8, xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+40], xmm0
$LN25@mergeSort:

; 61   : 
; 62   : 	PIXEL_COMPARE_AND_SWAP(12, 13);

	vmovss	xmm1, DWORD PTR [rcx+48]
	vmovss	xmm2, DWORD PTR [rcx+52]
	vcomiss	xmm1, xmm2
	vmovaps	xmm0, xmm1
	jbe	SHORT $LN26@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm2
	vmovaps	xmm0, xmm2
	vmovaps	xmm2, xmm1
	vmovss	DWORD PTR [rcx+52], xmm1
$LN26@mergeSort:

; 63   : 	PIXEL_COMPARE_AND_SWAP(14, 15);

	vmovss	xmm1, DWORD PTR [rcx+56]
	vmovss	xmm5, DWORD PTR [rcx+60]
	vcomiss	xmm1, xmm5
	vmovaps	xmm6, xmm1
	jbe	SHORT $LN27@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm5
	vmovaps	xmm6, xmm5
	vmovaps	xmm5, xmm1
	vmovss	DWORD PTR [rcx+60], xmm1
$LN27@mergeSort:

; 64   : 	PIXEL_COMPARE_AND_SWAP(12, 14);

	vcomiss	xmm0, xmm6
	vmovaps	xmm1, xmm6
	jbe	SHORT $LN28@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm0
	vmovaps	xmm1, xmm0
	vmovaps	xmm0, xmm6
	vmovss	DWORD PTR [rcx+48], xmm6
$LN28@mergeSort:

; 65   : 	PIXEL_COMPARE_AND_SWAP(13, 15);

	vcomiss	xmm2, xmm5
	vmovaps	xmm6, xmm2
	jbe	SHORT $LN29@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm5
	vmovaps	xmm6, xmm5
	vmovaps	xmm5, xmm2
	vmovss	DWORD PTR [rcx+60], xmm2
$LN29@mergeSort:

; 66   : 	PIXEL_COMPARE_AND_SWAP(13, 14);

	vcomiss	xmm6, xmm1
	vmovaps	xmm7, xmm6
	jbe	SHORT $LN30@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm1
	vmovaps	xmm7, xmm1
	vmovaps	xmm1, xmm6
	vmovss	DWORD PTR [rcx+56], xmm6
$LN30@mergeSort:

; 67   : 
; 68   : 	PIXEL_COMPARE_AND_SWAP(8, 12);

	vcomiss	xmm4, xmm0
	vmovaps	xmm6, xmm0
	jbe	SHORT $LN31@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm4
	vmovaps	xmm6, xmm4
	vmovaps	xmm4, xmm0
	vmovss	DWORD PTR [rcx+32], xmm0
$LN31@mergeSort:

; 69   : 	PIXEL_COMPARE_AND_SWAP(9, 13); 

	vcomiss	xmm8, xmm7
	vmovaps	xmm2, xmm7
	jbe	SHORT $LN32@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm8
	vmovaps	xmm2, xmm8
	vmovaps	xmm8, xmm7
	vmovss	DWORD PTR [rcx+36], xmm7
$LN32@mergeSort:

; 70   : 	PIXEL_COMPARE_AND_SWAP(10, 14);

	vcomiss	xmm3, xmm1
	vmovaps	xmm7, xmm3
	jbe	SHORT $LN33@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm1
	vmovaps	xmm7, xmm1
	vmovaps	xmm1, xmm3
	vmovss	DWORD PTR [rcx+56], xmm3
$LN33@mergeSort:

; 71   : 	PIXEL_COMPARE_AND_SWAP(11, 15);

	vmovss	xmm0, DWORD PTR [rcx+44]
	vcomiss	xmm0, xmm5
	jbe	SHORT $LN34@mergeSort
	vmovss	DWORD PTR [rcx+60], xmm0
	vmovaps	xmm0, xmm5
	vmovss	DWORD PTR [rcx+44], xmm5
$LN34@mergeSort:

; 72   : 
; 73   : 	PIXEL_COMPARE_AND_SWAP(10, 12); 

	vcomiss	xmm7, xmm6
	vmovaps	xmm5, xmm7
	jbe	SHORT $LN35@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm6
	vmovaps	xmm5, xmm6
	vmovaps	xmm6, xmm7
	vmovss	DWORD PTR [rcx+48], xmm7
$LN35@mergeSort:

; 74   : 	PIXEL_COMPARE_AND_SWAP(11, 13);

	vcomiss	xmm0, xmm2
	vmovaps	xmm3, xmm0
	jbe	SHORT $LN36@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm2
	vmovaps	xmm3, xmm2
	vmovaps	xmm2, xmm0
	vmovss	DWORD PTR [rcx+52], xmm0
$LN36@mergeSort:

; 75   : 
; 76   : 	PIXEL_COMPARE_AND_SWAP(9, 10);

	vcomiss	xmm8, xmm5
	vmovaps	xmm7, xmm8
	jbe	SHORT $LN37@mergeSort
	vmovss	DWORD PTR [rcx+36], xmm5
	vmovaps	xmm7, xmm5
	vmovaps	xmm5, xmm8
	vmovss	DWORD PTR [rcx+40], xmm8
$LN37@mergeSort:

; 77   : 	PIXEL_COMPARE_AND_SWAP(11, 12);

	vcomiss	xmm3, xmm6
	vmovaps	xmm11, xmm3
	jbe	SHORT $LN38@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm6
	vmovaps	xmm11, xmm6
	vmovaps	xmm6, xmm3
	vmovss	DWORD PTR [rcx+48], xmm3
$LN38@mergeSort:

; 78   : 	PIXEL_COMPARE_AND_SWAP(13, 14);

	vcomiss	xmm2, xmm1
	vmovaps	xmm3, xmm2
	jbe	SHORT $LN39@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm1
	vmovaps	xmm3, xmm1
	vmovaps	xmm1, xmm2
	vmovss	DWORD PTR [rcx+56], xmm2
$LN39@mergeSort:

; 79   : 
; 80   : 
; 81   : 	PIXEL_COMPARE_AND_SWAP(0, 8); 

	vmovss	xmm0, DWORD PTR [rcx]
	vcomiss	xmm0, xmm4
	jbe	SHORT $LN40@mergeSort
	vmovss	DWORD PTR [rcx], xmm4
	vmovaps	xmm4, xmm0
	vmovss	DWORD PTR [rcx+32], xmm0
$LN40@mergeSort:

; 82   : 	PIXEL_COMPARE_AND_SWAP(1, 9); 

	vmovss	xmm0, DWORD PTR [rcx+4]
	vcomiss	xmm0, xmm7
	jbe	SHORT $LN41@mergeSort
	vmovss	DWORD PTR [rcx+4], xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+36], xmm0
$LN41@mergeSort:

; 83   : 	PIXEL_COMPARE_AND_SWAP(2, 10); 

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm5
	jbe	SHORT $LN42@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+40], xmm0
$LN42@mergeSort:

; 84   : 	PIXEL_COMPARE_AND_SWAP(3, 11); 

	vmovss	xmm0, DWORD PTR [rcx+12]
	vcomiss	xmm0, xmm11
	jbe	SHORT $LN43@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm11
	vmovaps	xmm11, xmm0
	vmovss	DWORD PTR [rcx+44], xmm0
$LN43@mergeSort:

; 85   : 	PIXEL_COMPARE_AND_SWAP(4, 12); 

	vmovss	xmm0, DWORD PTR [rcx+16]
	vcomiss	xmm0, xmm6
	jbe	SHORT $LN44@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm0
	vmovaps	xmm0, xmm6
	vmovss	DWORD PTR [rcx+16], xmm6
$LN44@mergeSort:

; 86   : 	PIXEL_COMPARE_AND_SWAP(5, 13); 

	vmovss	xmm2, DWORD PTR [rcx+20]
	vcomiss	xmm2, xmm3
	jbe	SHORT $LN45@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm2
	vmovaps	xmm2, xmm3
	vmovss	DWORD PTR [rcx+20], xmm3
$LN45@mergeSort:

; 87   : 	PIXEL_COMPARE_AND_SWAP(6, 14); 

	vmovss	xmm3, DWORD PTR [rcx+24]
	vcomiss	xmm3, xmm1
	jbe	SHORT $LN46@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm3
	vmovaps	xmm3, xmm1
	vmovss	DWORD PTR [rcx+24], xmm1
$LN46@mergeSort:

; 88   : 	PIXEL_COMPARE_AND_SWAP(7, 15); 

	vmovss	xmm1, DWORD PTR [rcx+28]
	vmovss	xmm6, DWORD PTR [rcx+60]
	vcomiss	xmm1, xmm6
	jbe	SHORT $LN47@mergeSort
	vmovss	DWORD PTR [rcx+60], xmm1
	vmovaps	xmm1, xmm6
	vmovss	DWORD PTR [rcx+28], xmm6
$LN47@mergeSort:

; 89   : 
; 90   : 
; 91   : 	PIXEL_COMPARE_AND_SWAP(4, 8); 

	vcomiss	xmm0, xmm4
	vmovaps	xmm8, xmm0
	jbe	SHORT $LN48@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm4
	vmovaps	xmm8, xmm4
	vmovaps	xmm4, xmm0
	vmovss	DWORD PTR [rcx+32], xmm0
$LN48@mergeSort:

; 92   : 	PIXEL_COMPARE_AND_SWAP(5, 9); 

	vcomiss	xmm2, xmm7
	vmovaps	xmm9, xmm2
	jbe	SHORT $LN49@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm7
	vmovaps	xmm9, xmm7
	vmovaps	xmm7, xmm2
	vmovss	DWORD PTR [rcx+36], xmm2
$LN49@mergeSort:

; 93   : 	PIXEL_COMPARE_AND_SWAP(6, 10); 

	vcomiss	xmm3, xmm5
	vmovaps	xmm2, xmm3
	jbe	SHORT $LN50@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm5
	vmovaps	xmm2, xmm5
	vmovaps	xmm5, xmm3
	vmovss	DWORD PTR [rcx+40], xmm3
$LN50@mergeSort:

; 94   : 	PIXEL_COMPARE_AND_SWAP(7, 11); 

	vcomiss	xmm1, xmm11
	vmovaps	xmm3, xmm1
	jbe	SHORT $LN51@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm11
	vmovaps	xmm3, xmm11
	vmovaps	xmm11, xmm1
	vmovss	DWORD PTR [rcx+44], xmm1
$LN51@mergeSort:

; 95   : 
; 96   : 	PIXEL_COMPARE_AND_SWAP(2, 4); 

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm8
	vmovaps	xmm14, xmm0
	jbe	SHORT $LN52@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm8
	vmovaps	xmm14, xmm8
	vmovaps	xmm8, xmm0
	vmovss	DWORD PTR [rcx+16], xmm0
$LN52@mergeSort:

; 97   : 	PIXEL_COMPARE_AND_SWAP(3, 5); 

	vmovss	xmm0, DWORD PTR [rcx+12]
	vcomiss	xmm0, xmm9
	vmovaps	xmm13, xmm0
	jbe	SHORT $LN53@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm9
	vmovaps	xmm13, xmm9
	vmovaps	xmm9, xmm0
	vmovss	DWORD PTR [rcx+20], xmm0
$LN53@mergeSort:

; 98   : 	PIXEL_COMPARE_AND_SWAP(6, 8);

	vcomiss	xmm2, xmm4
	vmovaps	xmm12, xmm2
	jbe	SHORT $LN54@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm4
	vmovaps	xmm12, xmm4
	vmovaps	xmm4, xmm2
	vmovss	DWORD PTR [rcx+32], xmm2
$LN54@mergeSort:

; 99   : 	PIXEL_COMPARE_AND_SWAP(7, 9);

	vcomiss	xmm3, xmm7
	vmovaps	xmm10, xmm3
	jbe	SHORT $LN55@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm7
	vmovaps	xmm10, xmm7
	vmovaps	xmm7, xmm3
	vmovss	DWORD PTR [rcx+36], xmm3
$LN55@mergeSort:

; 100  : 	PIXEL_COMPARE_AND_SWAP(10, 12); 

	vmovss	xmm2, DWORD PTR [rcx+48]
	vcomiss	xmm5, xmm2
	vmovaps	xmm6, xmm5
	jbe	SHORT $LN56@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm2
	vmovaps	xmm6, xmm2
	vmovaps	xmm2, xmm5
	vmovss	DWORD PTR [rcx+48], xmm5
$LN56@mergeSort:

; 101  : 	PIXEL_COMPARE_AND_SWAP(11, 13); 

	vmovss	xmm3, DWORD PTR [rcx+52]
	vcomiss	xmm11, xmm3
	vmovaps	xmm1, xmm11
	jbe	SHORT $LN57@mergeSort
	vmovss	DWORD PTR [rcx+44], xmm3
	vmovaps	xmm1, xmm3
	vmovaps	xmm3, xmm11
	vmovss	DWORD PTR [rcx+52], xmm11
$LN57@mergeSort:

; 102  : 
; 103  : 	PIXEL_COMPARE_AND_SWAP(1, 2); 

	vmovss	xmm0, DWORD PTR [rcx+4]
	vcomiss	xmm0, xmm14
	jbe	SHORT $LN58@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm0
	vmovss	DWORD PTR [rcx+4], xmm14
$LN58@mergeSort:

; 104  : 	PIXEL_COMPARE_AND_SWAP(3, 4); 

	vcomiss	xmm13, xmm8
	jbe	SHORT $LN59@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm13
	vmovss	DWORD PTR [rcx+12], xmm8
$LN59@mergeSort:

; 105  : 	PIXEL_COMPARE_AND_SWAP(5, 6); 

	vcomiss	xmm9, xmm12
	jbe	SHORT $LN60@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm9
	vmovss	DWORD PTR [rcx+20], xmm12
$LN60@mergeSort:

; 106  : 	PIXEL_COMPARE_AND_SWAP(7, 8); 

	vcomiss	xmm10, xmm4
	jbe	SHORT $LN61@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm10
	vmovss	DWORD PTR [rcx+28], xmm4
$LN61@mergeSort:

; 107  : 	PIXEL_COMPARE_AND_SWAP(9, 10); 

	vcomiss	xmm7, xmm6
	jbe	SHORT $LN62@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm7
	vmovss	DWORD PTR [rcx+36], xmm6
$LN62@mergeSort:

; 108  : 	PIXEL_COMPARE_AND_SWAP(11, 12); 

	vcomiss	xmm1, xmm2
	jbe	SHORT $LN63@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm1
	vmovss	DWORD PTR [rcx+44], xmm2
$LN63@mergeSort:

; 109  : 	PIXEL_COMPARE_AND_SWAP(13, 14); 

	vmovss	xmm0, DWORD PTR [rcx+56]
	vcomiss	xmm3, xmm0
	jbe	SHORT $LN64@mergeSort
	vmovss	DWORD PTR [rcx+56], xmm3
	vmovss	DWORD PTR [rcx+52], xmm0
$LN64@mergeSort:

; 110  : 
; 111  : // Eddig 8x8-as (16 bemenet)
; 112  : 
; 113  : 	//4x4
; 114  : 	PIXEL_COMPARE_AND_SWAP(16, 17);

	vmovss	xmm0, DWORD PTR [rcx+64]
	vmovss	xmm1, DWORD PTR [rcx+68]
	vcomiss	xmm0, xmm1
	vmovaps	xmm2, xmm0
	jbe	SHORT $LN65@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm1
	vmovaps	xmm2, xmm1
	vmovaps	xmm1, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN65@mergeSort:

; 115  : 
; 116  : 
; 117  : 	PIXEL_COMPARE_AND_SWAP(16, 18);

	vmovss	xmm3, DWORD PTR [rcx+72]
	vcomiss	xmm2, xmm3
	jbe	SHORT $LN66@mergeSort
	vmovaps	xmm0, xmm3
	vmovss	DWORD PTR [rcx+64], xmm3
	vmovaps	xmm3, xmm2
	vmovss	DWORD PTR [rcx+72], xmm2
	vmovaps	xmm2, xmm0
$LN66@mergeSort:

; 118  : 	PIXEL_COMPARE_AND_SWAP(17, 19);

	vmovss	xmm0, DWORD PTR [rcx+76]
	vcomiss	xmm1, xmm0
	jbe	SHORT $LN67@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm1
	vmovaps	xmm1, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN67@mergeSort:

; 119  : 
; 120  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vcomiss	xmm1, xmm3
	vmovaps	xmm4, xmm1
	jbe	SHORT $LN68@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm3
	vmovaps	xmm4, xmm3
	vmovaps	xmm3, xmm1
	vmovss	DWORD PTR [rcx+72], xmm1
$LN68@mergeSort:

; 121  : 
; 122  : 
; 123  : 	PIXEL_COMPARE_AND_SWAP(16, 20);

	vmovss	xmm14, DWORD PTR [rcx+80]
	vcomiss	xmm2, xmm14
	vmovaps	xmm6, xmm2
	jbe	SHORT $LN69@mergeSort
	vmovaps	xmm6, xmm14
	vmovss	DWORD PTR [rcx+64], xmm6
	vmovss	DWORD PTR [rcx+80], xmm2
	vmovaps	xmm14, xmm2
$LN69@mergeSort:

; 124  : 	PIXEL_COMPARE_AND_SWAP(17, 21);

	vmovss	xmm9, DWORD PTR [rcx+84]
	vcomiss	xmm4, xmm9
	vmovaps	xmm0, xmm4
	jbe	SHORT $LN70@mergeSort
	vmovaps	xmm0, xmm9
	vmovss	DWORD PTR [rcx+68], xmm0
	vmovss	DWORD PTR [rcx+84], xmm4
	vmovaps	xmm9, xmm4
$LN70@mergeSort:

; 125  : 
; 126  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vcomiss	xmm0, xmm3
	vmovaps	xmm1, xmm0
	jbe	SHORT $LN71@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm3
	vmovaps	xmm1, xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+72], xmm0
$LN71@mergeSort:

; 127  : 
; 128  : 
; 129  : 	PIXEL_COMPARE_AND_SWAP(16, 24);

	vmovss	xmm0, DWORD PTR [rcx+96]
	vcomiss	xmm6, xmm0
	jbe	SHORT $LN72@mergeSort
	vmovss	DWORD PTR [rcx+96], xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+64], xmm0
$LN72@mergeSort:

; 130  : 
; 131  : 	PIXEL_COMPARE_AND_SWAP(17, 18);

	vcomiss	xmm1, xmm3
	vmovaps	xmm2, xmm1
	jbe	SHORT $LN73@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm3
	vmovaps	xmm2, xmm3
	vmovaps	xmm3, xmm1
	vmovss	DWORD PTR [rcx+72], xmm1
$LN73@mergeSort:

; 132  : 
; 133  : // 16x16 
; 134  : 	PIXEL_COMPARE_AND_SWAP(0, 16);

	vmovss	xmm0, DWORD PTR [rcx]
	vcomiss	xmm0, xmm6
	jbe	SHORT $LN74@mergeSort
	vmovss	DWORD PTR [rcx], xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+64], xmm0
$LN74@mergeSort:

; 135  : 	PIXEL_COMPARE_AND_SWAP(1, 17);

	vmovss	xmm0, DWORD PTR [rcx+4]
	vcomiss	xmm0, xmm2
	jbe	SHORT $LN75@mergeSort
	vmovss	DWORD PTR [rcx+4], xmm2
	vmovaps	xmm2, xmm0
	vmovss	DWORD PTR [rcx+68], xmm0
$LN75@mergeSort:

; 136  : 	PIXEL_COMPARE_AND_SWAP(2, 18);

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm3
	jbe	SHORT $LN76@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm3
	vmovaps	xmm3, xmm0
	vmovss	DWORD PTR [rcx+72], xmm0
$LN76@mergeSort:

; 137  : 	PIXEL_COMPARE_AND_SWAP(3, 19);

	vmovss	xmm0, DWORD PTR [rcx+12]
	vmovss	xmm7, DWORD PTR [rcx+76]
	vcomiss	xmm0, xmm7
	jbe	SHORT $LN77@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm7
	vmovaps	xmm7, xmm0
	vmovss	DWORD PTR [rcx+76], xmm0
$LN77@mergeSort:

; 138  : 	PIXEL_COMPARE_AND_SWAP(4, 20);

	vmovss	xmm0, DWORD PTR [rcx+16]
	vcomiss	xmm0, xmm14
	jbe	SHORT $LN78@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm14
	vmovaps	xmm14, xmm0
	vmovss	DWORD PTR [rcx+80], xmm0
$LN78@mergeSort:

; 139  : 	PIXEL_COMPARE_AND_SWAP(5, 21);

	vmovss	xmm0, DWORD PTR [rcx+20]
	vcomiss	xmm0, xmm9
	jbe	SHORT $LN79@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm9
	vmovaps	xmm9, xmm0
	vmovss	DWORD PTR [rcx+84], xmm0
$LN79@mergeSort:

; 140  : 	PIXEL_COMPARE_AND_SWAP(6, 22);

	vmovss	xmm0, DWORD PTR [rcx+24]
	vmovss	xmm1, DWORD PTR [rcx+88]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN80@mergeSort
	vmovss	DWORD PTR [rcx+88], xmm0
	vmovss	DWORD PTR [rcx+24], xmm1
$LN80@mergeSort:

; 141  : 	PIXEL_COMPARE_AND_SWAP(7, 23);

	vmovss	xmm0, DWORD PTR [rcx+28]
	vmovss	xmm1, DWORD PTR [rcx+92]
	vcomiss	xmm0, xmm1
	jbe	SHORT $LN81@mergeSort
	vmovss	DWORD PTR [rcx+92], xmm0
	vmovss	DWORD PTR [rcx+28], xmm1
$LN81@mergeSort:

; 142  : 	PIXEL_COMPARE_AND_SWAP(8, 24);

	vmovss	xmm5, DWORD PTR [rcx+32]
	vmovss	xmm0, DWORD PTR [rcx+96]
	vcomiss	xmm5, xmm0
	jbe	SHORT $LN82@mergeSort
	vmovss	DWORD PTR [rcx+96], xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+32], xmm0
$LN82@mergeSort:

; 143  : 
; 144  : 
; 145  : 	PIXEL_COMPARE_AND_SWAP(8, 16);

	vcomiss	xmm5, xmm6
	jbe	SHORT $LN83@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm5
	vmovaps	xmm5, xmm6
	vmovss	DWORD PTR [rcx+32], xmm6
$LN83@mergeSort:

; 146  : 	PIXEL_COMPARE_AND_SWAP(9, 17);

	vmovss	xmm8, DWORD PTR [rcx+36]
	vcomiss	xmm8, xmm2
	jbe	SHORT $LN84@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm8
	vmovaps	xmm8, xmm2
	vmovss	DWORD PTR [rcx+36], xmm2
$LN84@mergeSort:

; 147  : 	PIXEL_COMPARE_AND_SWAP(10, 18);

	vmovss	xmm13, DWORD PTR [rcx+40]
	vcomiss	xmm13, xmm3
	jbe	SHORT $LN85@mergeSort
	vmovss	DWORD PTR [rcx+72], xmm13
	vmovaps	xmm13, xmm3
	vmovss	DWORD PTR [rcx+40], xmm3
$LN85@mergeSort:

; 148  : 	PIXEL_COMPARE_AND_SWAP(11, 19);

	vmovss	xmm4, DWORD PTR [rcx+44]
	vcomiss	xmm4, xmm7
	jbe	SHORT $LN86@mergeSort
	vmovss	DWORD PTR [rcx+76], xmm4
	vmovaps	xmm4, xmm7
	vmovss	DWORD PTR [rcx+44], xmm7
$LN86@mergeSort:

; 149  : 	PIXEL_COMPARE_AND_SWAP(12, 20);

	vmovss	xmm0, DWORD PTR [rcx+48]
	vcomiss	xmm0, xmm14
	vmovaps	xmm6, xmm0
	jbe	SHORT $LN87@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm14
	vmovaps	xmm6, xmm14
	vmovaps	xmm14, xmm0
	vmovss	DWORD PTR [rcx+80], xmm0
$LN87@mergeSort:

; 150  : 	PIXEL_COMPARE_AND_SWAP(13, 21);

	vmovss	xmm12, DWORD PTR [rcx+52]
	vcomiss	xmm12, xmm9
	jbe	SHORT $LN88@mergeSort
	vmovss	DWORD PTR [rcx+84], xmm12
	vmovaps	xmm12, xmm9
	vmovss	DWORD PTR [rcx+52], xmm9
$LN88@mergeSort:

; 151  : 
; 152  : 
; 153  : 	PIXEL_COMPARE_AND_SWAP(4, 8);

	vmovss	xmm0, DWORD PTR [rcx+16]
	vcomiss	xmm0, xmm5
	vmovaps	xmm11, xmm0
	jbe	SHORT $LN89@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm5
	vmovaps	xmm11, xmm5
	vmovaps	xmm5, xmm0
	vmovss	DWORD PTR [rcx+32], xmm0
$LN89@mergeSort:

; 154  : 	PIXEL_COMPARE_AND_SWAP(5, 9);

	vmovss	xmm0, DWORD PTR [rcx+20]
	vcomiss	xmm0, xmm8
	vmovaps	xmm10, xmm0
	jbe	SHORT $LN90@mergeSort
	vmovss	DWORD PTR [rcx+20], xmm8
	vmovaps	xmm10, xmm8
	vmovaps	xmm8, xmm0
	vmovss	DWORD PTR [rcx+36], xmm0
$LN90@mergeSort:

; 155  : 	PIXEL_COMPARE_AND_SWAP(6, 10);

	vmovss	xmm0, DWORD PTR [rcx+24]
	vcomiss	xmm0, xmm13
	vmovaps	xmm1, xmm0
	jbe	SHORT $LN91@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm13
	vmovaps	xmm1, xmm13
	vmovaps	xmm13, xmm0
	vmovss	DWORD PTR [rcx+40], xmm0
$LN91@mergeSort:

; 156  : 	PIXEL_COMPARE_AND_SWAP(7, 11);

	vmovss	xmm0, DWORD PTR [rcx+28]
	vcomiss	xmm0, xmm4
	vmovaps	xmm2, xmm0
	jbe	SHORT $LN92@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm4
	vmovaps	xmm2, xmm4
	vmovaps	xmm4, xmm0
	vmovss	DWORD PTR [rcx+44], xmm0
$LN92@mergeSort:

; 157  : 
; 158  : 	PIXEL_COMPARE_AND_SWAP(12, 16);

	vmovss	xmm0, DWORD PTR [rcx+64]
	vcomiss	xmm6, xmm0
	jbe	SHORT $LN93@mergeSort
	vmovss	DWORD PTR [rcx+64], xmm6
	vmovaps	xmm6, xmm0
	vmovss	DWORD PTR [rcx+48], xmm0
$LN93@mergeSort:

; 159  : 	PIXEL_COMPARE_AND_SWAP(13, 17);

	vmovss	xmm0, DWORD PTR [rcx+68]
	vcomiss	xmm12, xmm0
	jbe	SHORT $LN94@mergeSort
	vmovss	DWORD PTR [rcx+68], xmm12
	vmovaps	xmm12, xmm0
	vmovss	DWORD PTR [rcx+52], xmm0
$LN94@mergeSort:

; 160  : 
; 161  : 	//PIXEL_COMPARE_AND_SWAP(20, 21);
; 162  : 	PIXEL_COMPARE_AND_SWAP(20, 24);

	vmovss	xmm0, DWORD PTR [rcx+96]
	vcomiss	xmm14, xmm0
	jbe	SHORT $LN95@mergeSort
	vmovss	DWORD PTR [rcx+96], xmm14
	vmovss	DWORD PTR [rcx+80], xmm0
$LN95@mergeSort:

; 163  : 
; 164  : 
; 165  : 	PIXEL_COMPARE_AND_SWAP(2, 4);

	vmovss	xmm0, DWORD PTR [rcx+8]
	vcomiss	xmm0, xmm11
	vmovaps	xmm9, xmm0
	jbe	SHORT $LN96@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm11
	vmovaps	xmm9, xmm11
	vmovaps	xmm11, xmm0
	vmovss	DWORD PTR [rcx+16], xmm0
$LN96@mergeSort:

; 166  : 	PIXEL_COMPARE_AND_SWAP(3, 5);

	vmovss	xmm0, DWORD PTR [rcx+12]
	vcomiss	xmm0, xmm10
	vmovaps	xmm7, xmm0
	jbe	SHORT $LN97@mergeSort
	vmovss	DWORD PTR [rcx+12], xmm10
	vmovaps	xmm7, xmm10
	vmovaps	xmm10, xmm0
	vmovss	DWORD PTR [rcx+20], xmm0
$LN97@mergeSort:

; 167  : 	PIXEL_COMPARE_AND_SWAP(6, 8);

	vcomiss	xmm1, xmm5
	vmovaps	xmm3, xmm1
	jbe	SHORT $LN98@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm5
	vmovaps	xmm3, xmm5
	vmovaps	xmm5, xmm1
	vmovss	DWORD PTR [rcx+32], xmm1
$LN98@mergeSort:

; 168  : 	PIXEL_COMPARE_AND_SWAP(7, 9);

	vcomiss	xmm2, xmm8
	vmovaps	xmm1, xmm2
	jbe	SHORT $LN99@mergeSort
	vmovss	DWORD PTR [rcx+28], xmm8
	vmovaps	xmm1, xmm8
	vmovaps	xmm8, xmm2
	vmovss	DWORD PTR [rcx+36], xmm2
$LN99@mergeSort:

; 169  : 	PIXEL_COMPARE_AND_SWAP(10, 12);

	vcomiss	xmm13, xmm6
	vmovaps	xmm0, xmm13
	jbe	SHORT $LN100@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm6
	vmovaps	xmm0, xmm6
	vmovaps	xmm6, xmm13
	vmovss	DWORD PTR [rcx+48], xmm13
$LN100@mergeSort:

; 170  : 	PIXEL_COMPARE_AND_SWAP(11, 13);

	vcomiss	xmm4, xmm12
	jbe	SHORT $LN101@mergeSort
	vmovss	DWORD PTR [rcx+52], xmm4
	vmovaps	xmm4, xmm12
	vmovss	DWORD PTR [rcx+44], xmm12
$LN101@mergeSort:

; 171  : 
; 172  : 
; 173  : 
; 174  : 	PIXEL_COMPARE_AND_SWAP(1, 2);

	vmovss	xmm2, DWORD PTR [rcx+4]
	vcomiss	xmm2, xmm9
	jbe	SHORT $LN102@mergeSort
	vmovss	DWORD PTR [rcx+8], xmm2
	vmovss	DWORD PTR [rcx+4], xmm9
$LN102@mergeSort:

; 175  : 	PIXEL_COMPARE_AND_SWAP(3, 4);

	vcomiss	xmm7, xmm11
	jbe	SHORT $LN103@mergeSort
	vmovss	DWORD PTR [rcx+16], xmm7
	vmovss	DWORD PTR [rcx+12], xmm11
$LN103@mergeSort:

; 176  : 	PIXEL_COMPARE_AND_SWAP(5, 6);

	vcomiss	xmm10, xmm3
	jbe	SHORT $LN104@mergeSort
	vmovss	DWORD PTR [rcx+24], xmm10
	vmovss	DWORD PTR [rcx+20], xmm3
$LN104@mergeSort:

; 177  : 	PIXEL_COMPARE_AND_SWAP(7, 8);

	vcomiss	xmm1, xmm5
	jbe	SHORT $LN105@mergeSort
	vmovss	DWORD PTR [rcx+32], xmm1
	vmovss	DWORD PTR [rcx+28], xmm5
$LN105@mergeSort:

; 178  : 	PIXEL_COMPARE_AND_SWAP(9, 10);

	vcomiss	xmm8, xmm0
	jbe	SHORT $LN106@mergeSort
	vmovss	DWORD PTR [rcx+40], xmm8
	vmovss	DWORD PTR [rcx+36], xmm0
$LN106@mergeSort:

; 179  : 	PIXEL_COMPARE_AND_SWAP(11, 12);

	vcomiss	xmm4, xmm6
	jbe	SHORT $LN107@mergeSort
	vmovss	DWORD PTR [rcx+48], xmm4
	vmovss	DWORD PTR [rcx+44], xmm6
$LN107@mergeSort:

; 180  : }

	vmovaps	xmm7, XMMWORD PTR [rsp+112]
	lea	r11, QWORD PTR [rsp+152]
	vmovaps	xmm6, XMMWORD PTR [r11-24]
	vmovaps	xmm8, XMMWORD PTR [r11-56]
	vmovaps	xmm9, XMMWORD PTR [r11-72]
	vmovaps	xmm10, XMMWORD PTR [r11-88]
	vmovaps	xmm11, XMMWORD PTR [r11-104]
	vmovaps	xmm12, XMMWORD PTR [r11-120]
	vmovaps	xmm13, XMMWORD PTR [rsp+16]
	vmovaps	xmm14, XMMWORD PTR [rsp]
	mov	rsp, r11
	ret	0
?mergeSort@@YAXPEAM@Z ENDP				; mergeSort
_TEXT	ENDS
; Function compile flags: /Ogtpy
; File d:\d_strabi\d dokumentumai\bme\heterogén számítási rendszerek\hf\kismacska\hetero_hf_3\heterogen_hf_cpu_batchers\heterogen_hf_szp\_src\conv_filter.cpp
;	COMDAT ?medianFilter@@YAXHHHHHPEAM0@Z
_TEXT	SEGMENT
tv1712 = 32
tv1697 = 40
medianArray$1 = 48
__$ArrayPad$ = 160
imgHeight$ = 224
imgWidth$ = 232
imgWidthF$ = 240
imgFOffsetH$dead$ = 248
imgFOffsetW$dead$ = 256
imgFloatSrc$ = 264
imgFloatDst$ = 272
?medianFilter@@YAXHHHHHPEAM0@Z PROC			; medianFilter, COMDAT

; 381  : {

$LN43:
	mov	r11, rsp
	sub	rsp, 216				; 000000d8H
	mov	rax, QWORD PTR __security_cookie
	xor	rax, rsp
	mov	QWORD PTR __$ArrayPad$[rsp], rax
	mov	r10, QWORD PTR imgFloatDst$[rsp]

; 382  : 	// KÃ©p sorai
; 383  : 	for (int y=imgFOffsetH; y<(imgHeight + imgFOffsetH); y++)

	lea	r9d, DWORD PTR [rcx+2]
	cmp	r9d, 2
	jle	$LN3@medianFilt

; 381  : {

	mov	QWORD PTR [r11+8], rbx
	lea	eax, DWORD PTR [rdx*4]
	mov	QWORD PTR [r11+24], rbp
	mov	QWORD PTR [r11+32], rsi
	lea	esi, DWORD PTR [r8*4]
	mov	QWORD PTR [r11-8], rdi
	mov	QWORD PTR [r11-16], r12
	mov	QWORD PTR [r11-24], r13
	lea	r13d, DWORD PTR [r9-2]
	mov	r9, QWORD PTR imgFloatSrc$[rsp]
	cdqe
	shl	rax, 2
	mov	QWORD PTR tv1697[rsp], rax
	lea	eax, DWORD PTR [rdx*8+8]
	movsxd	rcx, eax
	mov	rax, QWORD PTR tv1697[rsp]
	mov	QWORD PTR [r11-32], r14
	mov	QWORD PTR [r11-40], r15
	lea	r11d, DWORD PTR [rdx+2]
	lea	r12, QWORD PTR [r10+rcx*4]
	mov	DWORD PTR tv1712[rsp], r11d
	mov	r15d, 8
	npad	6
$LL4@medianFilt:

; 384  : 		// KÃ©p oszlopai
; 385  : 		for (int x=imgFOffsetW; x<(imgWidth + imgFOffsetW); x++)

	cmp	r11d, 2
	jle	$LN2@medianFilt
	mov	r14d, r15d
	lea	ebp, DWORD PTR [r11-2]
	mov	rdi, r12
	npad	12
$LL7@medianFilt:

; 386  : 			// SzÃ­n komponensek
; 387  : 			for (int rgb = 0; rgb < 4; rgb++)

	xor	ebx, ebx
	npad	14
$LL10@medianFilt:

; 388  : 			{			
; 389  : 				float medianArray[25];
; 390  : 
; 391  : 				for (int medianY = 0; medianY < 5; medianY++) 

	lea	rdx, QWORD PTR medianArray$1[rsp+4]
	mov	r10d, 5
	lea	r8d, DWORD PTR [r14+rbx]
	npad	1
$LL13@medianFilt:

; 392  : 					for (int medianX = 0; medianX < 5; medianX++) 
; 393  : 						medianArray[5*medianY  + medianX] = imgFloatSrc[((y+(medianY-2))*imgWidthF + x + (medianX-2))*4 + rgb];

	movsxd	rax, r8d
	lea	rdx, QWORD PTR [rdx+20]
	mov	ecx, DWORD PTR [r9+rax*4-32]
	mov	DWORD PTR [rdx-24], ecx
	movsxd	rcx, r8d
	mov	eax, DWORD PTR [r9+rcx*4-16]
	mov	DWORD PTR [rdx-20], eax
	mov	eax, DWORD PTR [r9+rcx*4]
	mov	DWORD PTR [rdx-16], eax
	mov	eax, DWORD PTR [r9+rcx*4+16]
	mov	DWORD PTR [rdx-12], eax
	movsxd	rax, r8d
	add	r8d, esi
	mov	ecx, DWORD PTR [r9+rax*4+32]
	mov	DWORD PTR [rdx-8], ecx
	sub	r10, 1
	jne	SHORT $LL13@medianFilt

; 394  : 
; 395  : 				mergeSort(medianArray);

	lea	rcx, QWORD PTR medianArray$1[rsp]
	call	?mergeSort@@YAXPEAM@Z			; mergeSort

; 396  : 				//mergeSortFull(medianArray);
; 397  : 				imgFloatDst[(y*imgWidth + x) * 4 + rgb] = medianArray[MEDIAN];

	vmovss	xmm0, DWORD PTR medianArray$1[rsp+48]
	vmovss	DWORD PTR [rdi], xmm0
	add	rdi, 4
	inc	ebx
	cmp	ebx, 4
	jl	SHORT $LL10@medianFilt

; 384  : 		// KÃ©p oszlopai
; 385  : 		for (int x=imgFOffsetW; x<(imgWidth + imgFOffsetW); x++)

	add	r14d, 4
	sub	rbp, 1
	jne	$LL7@medianFilt
	mov	r11d, DWORD PTR tv1712[rsp]
	mov	rax, QWORD PTR tv1697[rsp]
$LN2@medianFilt:

; 382  : 	// KÃ©p sorai
; 383  : 	for (int y=imgFOffsetH; y<(imgHeight + imgFOffsetH); y++)

	add	r15d, esi
	add	r12, rax
	sub	r13, 1
	jne	$LL4@medianFilt
	mov	r15, QWORD PTR [rsp+176]
	mov	r14, QWORD PTR [rsp+184]
	mov	r13, QWORD PTR [rsp+192]
	mov	r12, QWORD PTR [rsp+200]
	mov	rdi, QWORD PTR [rsp+208]
	mov	rsi, QWORD PTR [rsp+248]
	mov	rbp, QWORD PTR [rsp+240]
	mov	rbx, QWORD PTR [rsp+224]
$LN3@medianFilt:

; 398  : 			}
; 399  : }

	mov	rcx, QWORD PTR __$ArrayPad$[rsp]
	xor	rcx, rsp
	call	__security_check_cookie
	add	rsp, 216				; 000000d8H
	ret	0
?medianFilter@@YAXHHHHHPEAM0@Z ENDP			; medianFilter
_TEXT	ENDS
END
